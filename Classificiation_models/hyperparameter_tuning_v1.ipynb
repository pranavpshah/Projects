{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scipy\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "import xgboost as xgb\n",
    "from hyperopt import tpe, hp, fmin, STATUS_OK,Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for file at wisdm-dataset/arff_files/phone/accel/data_1600_accel_phone.arffshape is: (321, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1601_accel_phone.arffshape is: (407, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1602_accel_phone.arffshape is: (424, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1603_accel_phone.arffshape is: (409, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1604_accel_phone.arffshape is: (321, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1605_accel_phone.arffshape is: (406, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1606_accel_phone.arffshape is: (321, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1607_accel_phone.arffshape is: (383, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1608_accel_phone.arffshape is: (482, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1609_accel_phone.arffshape is: (306, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1610_accel_phone.arffshape is: (404, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1611_accel_phone.arffshape is: (404, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1612_accel_phone.arffshape is: (404, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1613_accel_phone.arffshape is: (404, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1615_accel_phone.arffshape is: (404, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1616_accel_phone.arffshape is: (404, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1617_accel_phone.arffshape is: (404, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1618_accel_phone.arffshape is: (303, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1619_accel_phone.arffshape is: (407, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1620_accel_phone.arffshape is: (555, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1621_accel_phone.arffshape is: (408, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1622_accel_phone.arffshape is: (321, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1623_accel_phone.arffshape is: (455, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1624_accel_phone.arffshape is: (321, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1625_accel_phone.arffshape is: (574, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1626_accel_phone.arffshape is: (375, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1627_accel_phone.arffshape is: (775, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1628_accel_phone.arffshape is: (541, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1629_accel_phone.arffshape is: (348, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1630_accel_phone.arffshape is: (321, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1631_accel_phone.arffshape is: (321, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1632_accel_phone.arffshape is: (321, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1633_accel_phone.arffshape is: (429, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1634_accel_phone.arffshape is: (321, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1635_accel_phone.arffshape is: (644, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1636_accel_phone.arffshape is: (321, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1637_accel_phone.arffshape is: (324, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1638_accel_phone.arffshape is: (324, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1639_accel_phone.arffshape is: (324, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1640_accel_phone.arffshape is: (324, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1641_accel_phone.arffshape is: (803, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1642_accel_phone.arffshape is: (714, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1643_accel_phone.arffshape is: (759, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1644_accel_phone.arffshape is: (803, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1645_accel_phone.arffshape is: (803, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1646_accel_phone.arffshape is: (803, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1647_accel_phone.arffshape is: (409, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1648_accel_phone.arffshape is: (803, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1649_accel_phone.arffshape is: (409, 93)\n",
      "for file at wisdm-dataset/arff_files/phone/accel/data_1650_accel_phone.arffshape is: (803, 93)\n"
     ]
    }
   ],
   "source": [
    "phone_accel_df = pd.DataFrame()\n",
    "filenames = os.listdir('wisdm-dataset/arff_files/phone/accel')\n",
    "filenames.pop(0)\n",
    "for file in filenames:\n",
    "    path = \"wisdm-dataset/arff_files/phone/accel/\" + file\n",
    "    data = arff.loadarff(path)\n",
    "    df = pd.DataFrame(data[0])\n",
    "    print(\"for file at \" + path + \"shape is: \" + str(df.shape))\n",
    "    frames = [df, phone_accel_df]\n",
    "    phone_accel_df = pd.concat(frames, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23074, 93)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_accel_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_accel_old_column_names = phone_accel_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_accel_new_column_names = []\n",
    "for name in phone_accel_old_column_names:\n",
    "    phone_accel_new_column_names.append(name.replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y3</th>\n",
       "      <th>Y4</th>\n",
       "      <th>Y5</th>\n",
       "      <th>Y6</th>\n",
       "      <th>Y7</th>\n",
       "      <th>Y8</th>\n",
       "      <th>Y9</th>\n",
       "      <th>Z0</th>\n",
       "      <th>Z1</th>\n",
       "      <th>Z2</th>\n",
       "      <th>Z3</th>\n",
       "      <th>Z4</th>\n",
       "      <th>Z5</th>\n",
       "      <th>Z6</th>\n",
       "      <th>Z7</th>\n",
       "      <th>Z8</th>\n",
       "      <th>Z9</th>\n",
       "      <th>XAVG</th>\n",
       "      <th>YAVG</th>\n",
       "      <th>ZAVG</th>\n",
       "      <th>XPEAK</th>\n",
       "      <th>YPEAK</th>\n",
       "      <th>ZPEAK</th>\n",
       "      <th>XABSOLDEV</th>\n",
       "      <th>YABSOLDEV</th>\n",
       "      <th>ZABSOLDEV</th>\n",
       "      <th>XSTANDDEV</th>\n",
       "      <th>YSTANDDEV</th>\n",
       "      <th>ZSTANDDEV</th>\n",
       "      <th>XVAR</th>\n",
       "      <th>YVAR</th>\n",
       "      <th>ZVAR</th>\n",
       "      <th>XMFCC0</th>\n",
       "      <th>XMFCC1</th>\n",
       "      <th>XMFCC2</th>\n",
       "      <th>XMFCC3</th>\n",
       "      <th>XMFCC4</th>\n",
       "      <th>XMFCC5</th>\n",
       "      <th>XMFCC6</th>\n",
       "      <th>XMFCC7</th>\n",
       "      <th>XMFCC8</th>\n",
       "      <th>XMFCC9</th>\n",
       "      <th>XMFCC10</th>\n",
       "      <th>XMFCC11</th>\n",
       "      <th>XMFCC12</th>\n",
       "      <th>YMFCC0</th>\n",
       "      <th>YMFCC1</th>\n",
       "      <th>YMFCC2</th>\n",
       "      <th>YMFCC3</th>\n",
       "      <th>YMFCC4</th>\n",
       "      <th>YMFCC5</th>\n",
       "      <th>YMFCC6</th>\n",
       "      <th>YMFCC7</th>\n",
       "      <th>YMFCC8</th>\n",
       "      <th>YMFCC9</th>\n",
       "      <th>YMFCC10</th>\n",
       "      <th>YMFCC11</th>\n",
       "      <th>YMFCC12</th>\n",
       "      <th>ZMFCC0</th>\n",
       "      <th>ZMFCC1</th>\n",
       "      <th>ZMFCC2</th>\n",
       "      <th>ZMFCC3</th>\n",
       "      <th>ZMFCC4</th>\n",
       "      <th>ZMFCC5</th>\n",
       "      <th>ZMFCC6</th>\n",
       "      <th>ZMFCC7</th>\n",
       "      <th>ZMFCC8</th>\n",
       "      <th>ZMFCC9</th>\n",
       "      <th>ZMFCC10</th>\n",
       "      <th>ZMFCC11</th>\n",
       "      <th>ZMFCC12</th>\n",
       "      <th>XYCOS</th>\n",
       "      <th>XZCOS</th>\n",
       "      <th>YZCOS</th>\n",
       "      <th>XYCOR</th>\n",
       "      <th>XZCOR</th>\n",
       "      <th>YZCOR</th>\n",
       "      <th>RESULTANT</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'A'</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-1.29421</td>\n",
       "      <td>2.39763</td>\n",
       "      <td>7.43651</td>\n",
       "      <td>86.3636</td>\n",
       "      <td>89.5238</td>\n",
       "      <td>71.4815</td>\n",
       "      <td>3.79717</td>\n",
       "      <td>4.20119</td>\n",
       "      <td>3.60697</td>\n",
       "      <td>0.466331</td>\n",
       "      <td>0.458116</td>\n",
       "      <td>0.347447</td>\n",
       "      <td>0.682884</td>\n",
       "      <td>0.676843</td>\n",
       "      <td>0.589446</td>\n",
       "      <td>0.465170</td>\n",
       "      <td>0.657497</td>\n",
       "      <td>0.656441</td>\n",
       "      <td>0.654681</td>\n",
       "      <td>0.652221</td>\n",
       "      <td>0.649062</td>\n",
       "      <td>0.645209</td>\n",
       "      <td>0.640664</td>\n",
       "      <td>0.635433</td>\n",
       "      <td>0.629522</td>\n",
       "      <td>0.622937</td>\n",
       "      <td>0.615685</td>\n",
       "      <td>0.607773</td>\n",
       "      <td>0.444171</td>\n",
       "      <td>0.627817</td>\n",
       "      <td>0.626808</td>\n",
       "      <td>0.625128</td>\n",
       "      <td>0.622779</td>\n",
       "      <td>0.619763</td>\n",
       "      <td>0.616083</td>\n",
       "      <td>0.611744</td>\n",
       "      <td>0.606749</td>\n",
       "      <td>0.601105</td>\n",
       "      <td>0.594817</td>\n",
       "      <td>0.587892</td>\n",
       "      <td>0.580338</td>\n",
       "      <td>0.454504</td>\n",
       "      <td>0.642422</td>\n",
       "      <td>0.641390</td>\n",
       "      <td>0.639671</td>\n",
       "      <td>0.637267</td>\n",
       "      <td>0.634181</td>\n",
       "      <td>0.630416</td>\n",
       "      <td>0.625975</td>\n",
       "      <td>0.620864</td>\n",
       "      <td>0.615089</td>\n",
       "      <td>0.608655</td>\n",
       "      <td>0.601569</td>\n",
       "      <td>0.593838</td>\n",
       "      <td>0.395086</td>\n",
       "      <td>-0.200571</td>\n",
       "      <td>0.405282</td>\n",
       "      <td>0.501933</td>\n",
       "      <td>-0.073767</td>\n",
       "      <td>0.223811</td>\n",
       "      <td>11.51220</td>\n",
       "      <td>b'1650'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'A'</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.62912</td>\n",
       "      <td>-3.67598</td>\n",
       "      <td>-1.71978</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>65.3333</td>\n",
       "      <td>71.8519</td>\n",
       "      <td>2.97859</td>\n",
       "      <td>2.15444</td>\n",
       "      <td>3.16653</td>\n",
       "      <td>0.255185</td>\n",
       "      <td>0.193401</td>\n",
       "      <td>0.289781</td>\n",
       "      <td>0.505158</td>\n",
       "      <td>0.439773</td>\n",
       "      <td>0.538313</td>\n",
       "      <td>0.437150</td>\n",
       "      <td>0.617892</td>\n",
       "      <td>0.616899</td>\n",
       "      <td>0.615246</td>\n",
       "      <td>0.612934</td>\n",
       "      <td>0.609965</td>\n",
       "      <td>0.606344</td>\n",
       "      <td>0.602073</td>\n",
       "      <td>0.597157</td>\n",
       "      <td>0.591602</td>\n",
       "      <td>0.585414</td>\n",
       "      <td>0.578598</td>\n",
       "      <td>0.571163</td>\n",
       "      <td>0.389856</td>\n",
       "      <td>0.551044</td>\n",
       "      <td>0.550159</td>\n",
       "      <td>0.548684</td>\n",
       "      <td>0.546622</td>\n",
       "      <td>0.543975</td>\n",
       "      <td>0.540745</td>\n",
       "      <td>0.536937</td>\n",
       "      <td>0.532553</td>\n",
       "      <td>0.527599</td>\n",
       "      <td>0.522080</td>\n",
       "      <td>0.516002</td>\n",
       "      <td>0.509371</td>\n",
       "      <td>0.429256</td>\n",
       "      <td>0.606734</td>\n",
       "      <td>0.605760</td>\n",
       "      <td>0.604136</td>\n",
       "      <td>0.601866</td>\n",
       "      <td>0.598951</td>\n",
       "      <td>0.595395</td>\n",
       "      <td>0.591201</td>\n",
       "      <td>0.586374</td>\n",
       "      <td>0.580920</td>\n",
       "      <td>0.574843</td>\n",
       "      <td>0.568151</td>\n",
       "      <td>0.560850</td>\n",
       "      <td>0.794411</td>\n",
       "      <td>0.366282</td>\n",
       "      <td>0.108550</td>\n",
       "      <td>0.235529</td>\n",
       "      <td>0.026102</td>\n",
       "      <td>-0.366805</td>\n",
       "      <td>10.66480</td>\n",
       "      <td>b'1650'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'A'</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.41993</td>\n",
       "      <td>-3.07394</td>\n",
       "      <td>-2.68363</td>\n",
       "      <td>83.0435</td>\n",
       "      <td>67.2414</td>\n",
       "      <td>79.5455</td>\n",
       "      <td>2.56174</td>\n",
       "      <td>1.71211</td>\n",
       "      <td>2.75633</td>\n",
       "      <td>0.221399</td>\n",
       "      <td>0.152390</td>\n",
       "      <td>0.245360</td>\n",
       "      <td>0.470530</td>\n",
       "      <td>0.390372</td>\n",
       "      <td>0.495338</td>\n",
       "      <td>0.413661</td>\n",
       "      <td>0.584691</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.582188</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.577191</td>\n",
       "      <td>0.573764</td>\n",
       "      <td>0.569723</td>\n",
       "      <td>0.565071</td>\n",
       "      <td>0.559814</td>\n",
       "      <td>0.553958</td>\n",
       "      <td>0.547509</td>\n",
       "      <td>0.540474</td>\n",
       "      <td>0.331764</td>\n",
       "      <td>0.468933</td>\n",
       "      <td>0.468180</td>\n",
       "      <td>0.466925</td>\n",
       "      <td>0.465171</td>\n",
       "      <td>0.462918</td>\n",
       "      <td>0.460169</td>\n",
       "      <td>0.456928</td>\n",
       "      <td>0.453197</td>\n",
       "      <td>0.448982</td>\n",
       "      <td>0.444285</td>\n",
       "      <td>0.439113</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.396997</td>\n",
       "      <td>0.561138</td>\n",
       "      <td>0.560237</td>\n",
       "      <td>0.558735</td>\n",
       "      <td>0.556636</td>\n",
       "      <td>0.553940</td>\n",
       "      <td>0.550651</td>\n",
       "      <td>0.546772</td>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.537263</td>\n",
       "      <td>0.531643</td>\n",
       "      <td>0.525454</td>\n",
       "      <td>0.518702</td>\n",
       "      <td>0.848597</td>\n",
       "      <td>0.559720</td>\n",
       "      <td>0.454855</td>\n",
       "      <td>0.405486</td>\n",
       "      <td>-0.049683</td>\n",
       "      <td>-0.101471</td>\n",
       "      <td>10.11240</td>\n",
       "      <td>b'1650'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'A'</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.95552</td>\n",
       "      <td>-2.67376</td>\n",
       "      <td>-1.65992</td>\n",
       "      <td>70.3704</td>\n",
       "      <td>76.2500</td>\n",
       "      <td>71.5385</td>\n",
       "      <td>2.65143</td>\n",
       "      <td>1.86928</td>\n",
       "      <td>2.51211</td>\n",
       "      <td>0.230854</td>\n",
       "      <td>0.158261</td>\n",
       "      <td>0.228532</td>\n",
       "      <td>0.480472</td>\n",
       "      <td>0.397820</td>\n",
       "      <td>0.478050</td>\n",
       "      <td>0.424584</td>\n",
       "      <td>0.600131</td>\n",
       "      <td>0.599167</td>\n",
       "      <td>0.597562</td>\n",
       "      <td>0.595316</td>\n",
       "      <td>0.592433</td>\n",
       "      <td>0.588915</td>\n",
       "      <td>0.584767</td>\n",
       "      <td>0.579993</td>\n",
       "      <td>0.574598</td>\n",
       "      <td>0.568587</td>\n",
       "      <td>0.561967</td>\n",
       "      <td>0.554746</td>\n",
       "      <td>0.340917</td>\n",
       "      <td>0.481871</td>\n",
       "      <td>0.481097</td>\n",
       "      <td>0.479807</td>\n",
       "      <td>0.478004</td>\n",
       "      <td>0.475689</td>\n",
       "      <td>0.472865</td>\n",
       "      <td>0.469534</td>\n",
       "      <td>0.465701</td>\n",
       "      <td>0.461369</td>\n",
       "      <td>0.456542</td>\n",
       "      <td>0.451227</td>\n",
       "      <td>0.445429</td>\n",
       "      <td>0.394244</td>\n",
       "      <td>0.557247</td>\n",
       "      <td>0.556352</td>\n",
       "      <td>0.554861</td>\n",
       "      <td>0.552775</td>\n",
       "      <td>0.550098</td>\n",
       "      <td>0.546832</td>\n",
       "      <td>0.542981</td>\n",
       "      <td>0.538547</td>\n",
       "      <td>0.533538</td>\n",
       "      <td>0.527956</td>\n",
       "      <td>0.521810</td>\n",
       "      <td>0.515105</td>\n",
       "      <td>0.752024</td>\n",
       "      <td>0.515116</td>\n",
       "      <td>0.217559</td>\n",
       "      <td>0.143717</td>\n",
       "      <td>0.281892</td>\n",
       "      <td>-0.232531</td>\n",
       "      <td>10.19920</td>\n",
       "      <td>b'1650'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'A'</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.60716</td>\n",
       "      <td>-2.40619</td>\n",
       "      <td>-2.52186</td>\n",
       "      <td>101.0530</td>\n",
       "      <td>77.3913</td>\n",
       "      <td>105.0000</td>\n",
       "      <td>2.57757</td>\n",
       "      <td>1.22835</td>\n",
       "      <td>2.00075</td>\n",
       "      <td>0.217810</td>\n",
       "      <td>0.113445</td>\n",
       "      <td>0.185843</td>\n",
       "      <td>0.466701</td>\n",
       "      <td>0.336816</td>\n",
       "      <td>0.431095</td>\n",
       "      <td>0.384544</td>\n",
       "      <td>0.543536</td>\n",
       "      <td>0.542662</td>\n",
       "      <td>0.541208</td>\n",
       "      <td>0.539174</td>\n",
       "      <td>0.536563</td>\n",
       "      <td>0.533377</td>\n",
       "      <td>0.529620</td>\n",
       "      <td>0.525296</td>\n",
       "      <td>0.520410</td>\n",
       "      <td>0.514966</td>\n",
       "      <td>0.508971</td>\n",
       "      <td>0.502430</td>\n",
       "      <td>0.303598</td>\n",
       "      <td>0.429122</td>\n",
       "      <td>0.428433</td>\n",
       "      <td>0.427285</td>\n",
       "      <td>0.425679</td>\n",
       "      <td>0.423617</td>\n",
       "      <td>0.421102</td>\n",
       "      <td>0.418136</td>\n",
       "      <td>0.414722</td>\n",
       "      <td>0.410864</td>\n",
       "      <td>0.406567</td>\n",
       "      <td>0.401833</td>\n",
       "      <td>0.396670</td>\n",
       "      <td>0.373903</td>\n",
       "      <td>0.528495</td>\n",
       "      <td>0.527646</td>\n",
       "      <td>0.526232</td>\n",
       "      <td>0.524254</td>\n",
       "      <td>0.521715</td>\n",
       "      <td>0.518618</td>\n",
       "      <td>0.514965</td>\n",
       "      <td>0.510760</td>\n",
       "      <td>0.506009</td>\n",
       "      <td>0.500716</td>\n",
       "      <td>0.494887</td>\n",
       "      <td>0.488527</td>\n",
       "      <td>0.851431</td>\n",
       "      <td>0.679247</td>\n",
       "      <td>0.392689</td>\n",
       "      <td>0.364159</td>\n",
       "      <td>0.112605</td>\n",
       "      <td>-0.458078</td>\n",
       "      <td>9.78553</td>\n",
       "      <td>b'1650'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ACTIVITY     X0     X1     X2     X3     X4    X5   X6   X7   X8   X9  \\\n",
       "0     b'A'  0.230  0.235  0.385  0.085  0.055  0.01  0.0  0.0  0.0  0.0   \n",
       "1     b'A'  0.975  0.020  0.005  0.000  0.000  0.00  0.0  0.0  0.0  0.0   \n",
       "2     b'A'  1.000  0.000  0.000  0.000  0.000  0.00  0.0  0.0  0.0  0.0   \n",
       "3     b'A'  0.995  0.005  0.000  0.000  0.000  0.00  0.0  0.0  0.0  0.0   \n",
       "4     b'A'  0.990  0.010  0.000  0.000  0.000  0.00  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      Y0     Y1     Y2     Y3     Y4    Y5    Y6   Y7   Y8   Y9     Z0     Z1  \\\n",
       "0  0.170  0.030  0.085  0.360  0.275  0.07  0.01  0.0  0.0  0.0  0.040  0.050   \n",
       "1  0.660  0.255  0.075  0.005  0.005  0.00  0.00  0.0  0.0  0.0  0.370  0.280   \n",
       "2  0.555  0.415  0.030  0.000  0.000  0.00  0.00  0.0  0.0  0.0  0.440  0.360   \n",
       "3  0.500  0.400  0.100  0.000  0.000  0.00  0.00  0.0  0.0  0.0  0.330  0.350   \n",
       "4  0.380  0.580  0.040  0.000  0.000  0.00  0.00  0.0  0.0  0.0  0.485  0.365   \n",
       "\n",
       "      Z2     Z3     Z4     Z5    Z6     Z7    Z8    Z9     XAVG     YAVG  \\\n",
       "0  0.035  0.090  0.315  0.205  0.11  0.105  0.03  0.02 -1.29421  2.39763   \n",
       "1  0.225  0.085  0.040  0.000  0.00  0.000  0.00  0.00 -8.62912 -3.67598   \n",
       "2  0.150  0.045  0.005  0.000  0.00  0.000  0.00  0.00 -8.41993 -3.07394   \n",
       "3  0.240  0.075  0.005  0.000  0.00  0.000  0.00  0.00 -8.95552 -2.67376   \n",
       "4  0.115  0.025  0.010  0.000  0.00  0.000  0.00  0.00 -8.60716 -2.40619   \n",
       "\n",
       "      ZAVG     XPEAK    YPEAK     ZPEAK  XABSOLDEV  YABSOLDEV  ZABSOLDEV  \\\n",
       "0  7.43651   86.3636  89.5238   71.4815    3.79717    4.20119    3.60697   \n",
       "1 -1.71978   70.0000  65.3333   71.8519    2.97859    2.15444    3.16653   \n",
       "2 -2.68363   83.0435  67.2414   79.5455    2.56174    1.71211    2.75633   \n",
       "3 -1.65992   70.3704  76.2500   71.5385    2.65143    1.86928    2.51211   \n",
       "4 -2.52186  101.0530  77.3913  105.0000    2.57757    1.22835    2.00075   \n",
       "\n",
       "   XSTANDDEV  YSTANDDEV  ZSTANDDEV      XVAR      YVAR      ZVAR    XMFCC0  \\\n",
       "0   0.466331   0.458116   0.347447  0.682884  0.676843  0.589446  0.465170   \n",
       "1   0.255185   0.193401   0.289781  0.505158  0.439773  0.538313  0.437150   \n",
       "2   0.221399   0.152390   0.245360  0.470530  0.390372  0.495338  0.413661   \n",
       "3   0.230854   0.158261   0.228532  0.480472  0.397820  0.478050  0.424584   \n",
       "4   0.217810   0.113445   0.185843  0.466701  0.336816  0.431095  0.384544   \n",
       "\n",
       "     XMFCC1    XMFCC2    XMFCC3    XMFCC4    XMFCC5    XMFCC6    XMFCC7  \\\n",
       "0  0.657497  0.656441  0.654681  0.652221  0.649062  0.645209  0.640664   \n",
       "1  0.617892  0.616899  0.615246  0.612934  0.609965  0.606344  0.602073   \n",
       "2  0.584691  0.583752  0.582188  0.580000  0.577191  0.573764  0.569723   \n",
       "3  0.600131  0.599167  0.597562  0.595316  0.592433  0.588915  0.584767   \n",
       "4  0.543536  0.542662  0.541208  0.539174  0.536563  0.533377  0.529620   \n",
       "\n",
       "     XMFCC8    XMFCC9   XMFCC10   XMFCC11   XMFCC12    YMFCC0    YMFCC1  \\\n",
       "0  0.635433  0.629522  0.622937  0.615685  0.607773  0.444171  0.627817   \n",
       "1  0.597157  0.591602  0.585414  0.578598  0.571163  0.389856  0.551044   \n",
       "2  0.565071  0.559814  0.553958  0.547509  0.540474  0.331764  0.468933   \n",
       "3  0.579993  0.574598  0.568587  0.561967  0.554746  0.340917  0.481871   \n",
       "4  0.525296  0.520410  0.514966  0.508971  0.502430  0.303598  0.429122   \n",
       "\n",
       "     YMFCC2    YMFCC3    YMFCC4    YMFCC5    YMFCC6    YMFCC7    YMFCC8  \\\n",
       "0  0.626808  0.625128  0.622779  0.619763  0.616083  0.611744  0.606749   \n",
       "1  0.550159  0.548684  0.546622  0.543975  0.540745  0.536937  0.532553   \n",
       "2  0.468180  0.466925  0.465171  0.462918  0.460169  0.456928  0.453197   \n",
       "3  0.481097  0.479807  0.478004  0.475689  0.472865  0.469534  0.465701   \n",
       "4  0.428433  0.427285  0.425679  0.423617  0.421102  0.418136  0.414722   \n",
       "\n",
       "     YMFCC9   YMFCC10   YMFCC11   YMFCC12    ZMFCC0    ZMFCC1    ZMFCC2  \\\n",
       "0  0.601105  0.594817  0.587892  0.580338  0.454504  0.642422  0.641390   \n",
       "1  0.527599  0.522080  0.516002  0.509371  0.429256  0.606734  0.605760   \n",
       "2  0.448982  0.444285  0.439113  0.433470  0.396997  0.561138  0.560237   \n",
       "3  0.461369  0.456542  0.451227  0.445429  0.394244  0.557247  0.556352   \n",
       "4  0.410864  0.406567  0.401833  0.396670  0.373903  0.528495  0.527646   \n",
       "\n",
       "     ZMFCC3    ZMFCC4    ZMFCC5    ZMFCC6    ZMFCC7    ZMFCC8    ZMFCC9  \\\n",
       "0  0.639671  0.637267  0.634181  0.630416  0.625975  0.620864  0.615089   \n",
       "1  0.604136  0.601866  0.598951  0.595395  0.591201  0.586374  0.580920   \n",
       "2  0.558735  0.556636  0.553940  0.550651  0.546772  0.542308  0.537263   \n",
       "3  0.554861  0.552775  0.550098  0.546832  0.542981  0.538547  0.533538   \n",
       "4  0.526232  0.524254  0.521715  0.518618  0.514965  0.510760  0.506009   \n",
       "\n",
       "    ZMFCC10   ZMFCC11   ZMFCC12     XYCOS     XZCOS     YZCOS     XYCOR  \\\n",
       "0  0.608655  0.601569  0.593838  0.395086 -0.200571  0.405282  0.501933   \n",
       "1  0.574843  0.568151  0.560850  0.794411  0.366282  0.108550  0.235529   \n",
       "2  0.531643  0.525454  0.518702  0.848597  0.559720  0.454855  0.405486   \n",
       "3  0.527956  0.521810  0.515105  0.752024  0.515116  0.217559  0.143717   \n",
       "4  0.500716  0.494887  0.488527  0.851431  0.679247  0.392689  0.364159   \n",
       "\n",
       "      XZCOR     YZCOR  RESULTANT    class  \n",
       "0 -0.073767  0.223811   11.51220  b'1650'  \n",
       "1  0.026102 -0.366805   10.66480  b'1650'  \n",
       "2 -0.049683 -0.101471   10.11240  b'1650'  \n",
       "3  0.281892 -0.232531   10.19920  b'1650'  \n",
       "4  0.112605 -0.458078    9.78553  b'1650'  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_dict = dict(zip(phone_accel_old_column_names, phone_accel_new_column_names))\n",
    "phone_accel_df = phone_accel_df.rename(columns = replacement_dict)\n",
    "phone_accel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y3</th>\n",
       "      <th>Y4</th>\n",
       "      <th>Y5</th>\n",
       "      <th>Y6</th>\n",
       "      <th>Y7</th>\n",
       "      <th>Y8</th>\n",
       "      <th>Y9</th>\n",
       "      <th>Z0</th>\n",
       "      <th>Z1</th>\n",
       "      <th>Z2</th>\n",
       "      <th>Z3</th>\n",
       "      <th>Z4</th>\n",
       "      <th>Z5</th>\n",
       "      <th>Z6</th>\n",
       "      <th>Z7</th>\n",
       "      <th>Z8</th>\n",
       "      <th>Z9</th>\n",
       "      <th>XAVG</th>\n",
       "      <th>YAVG</th>\n",
       "      <th>ZAVG</th>\n",
       "      <th>XPEAK</th>\n",
       "      <th>YPEAK</th>\n",
       "      <th>ZPEAK</th>\n",
       "      <th>XABSOLDEV</th>\n",
       "      <th>YABSOLDEV</th>\n",
       "      <th>ZABSOLDEV</th>\n",
       "      <th>XSTANDDEV</th>\n",
       "      <th>YSTANDDEV</th>\n",
       "      <th>ZSTANDDEV</th>\n",
       "      <th>XVAR</th>\n",
       "      <th>YVAR</th>\n",
       "      <th>ZVAR</th>\n",
       "      <th>XMFCC0</th>\n",
       "      <th>XMFCC1</th>\n",
       "      <th>XMFCC2</th>\n",
       "      <th>XMFCC3</th>\n",
       "      <th>XMFCC4</th>\n",
       "      <th>XMFCC5</th>\n",
       "      <th>XMFCC6</th>\n",
       "      <th>XMFCC7</th>\n",
       "      <th>XMFCC8</th>\n",
       "      <th>XMFCC9</th>\n",
       "      <th>XMFCC10</th>\n",
       "      <th>XMFCC11</th>\n",
       "      <th>XMFCC12</th>\n",
       "      <th>YMFCC0</th>\n",
       "      <th>YMFCC1</th>\n",
       "      <th>YMFCC2</th>\n",
       "      <th>YMFCC3</th>\n",
       "      <th>YMFCC4</th>\n",
       "      <th>YMFCC5</th>\n",
       "      <th>YMFCC6</th>\n",
       "      <th>YMFCC7</th>\n",
       "      <th>YMFCC8</th>\n",
       "      <th>YMFCC9</th>\n",
       "      <th>YMFCC10</th>\n",
       "      <th>YMFCC11</th>\n",
       "      <th>YMFCC12</th>\n",
       "      <th>ZMFCC0</th>\n",
       "      <th>ZMFCC1</th>\n",
       "      <th>ZMFCC2</th>\n",
       "      <th>ZMFCC3</th>\n",
       "      <th>ZMFCC4</th>\n",
       "      <th>ZMFCC5</th>\n",
       "      <th>ZMFCC6</th>\n",
       "      <th>ZMFCC7</th>\n",
       "      <th>ZMFCC8</th>\n",
       "      <th>ZMFCC9</th>\n",
       "      <th>ZMFCC10</th>\n",
       "      <th>ZMFCC11</th>\n",
       "      <th>ZMFCC12</th>\n",
       "      <th>XYCOS</th>\n",
       "      <th>XZCOS</th>\n",
       "      <th>YZCOS</th>\n",
       "      <th>XYCOR</th>\n",
       "      <th>XZCOR</th>\n",
       "      <th>YZCOR</th>\n",
       "      <th>RESULTANT</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-1.29421</td>\n",
       "      <td>2.39763</td>\n",
       "      <td>7.43651</td>\n",
       "      <td>86.3636</td>\n",
       "      <td>89.5238</td>\n",
       "      <td>71.4815</td>\n",
       "      <td>3.79717</td>\n",
       "      <td>4.20119</td>\n",
       "      <td>3.60697</td>\n",
       "      <td>0.466331</td>\n",
       "      <td>0.458116</td>\n",
       "      <td>0.347447</td>\n",
       "      <td>0.682884</td>\n",
       "      <td>0.676843</td>\n",
       "      <td>0.589446</td>\n",
       "      <td>0.465170</td>\n",
       "      <td>0.657497</td>\n",
       "      <td>0.656441</td>\n",
       "      <td>0.654681</td>\n",
       "      <td>0.652221</td>\n",
       "      <td>0.649062</td>\n",
       "      <td>0.645209</td>\n",
       "      <td>0.640664</td>\n",
       "      <td>0.635433</td>\n",
       "      <td>0.629522</td>\n",
       "      <td>0.622937</td>\n",
       "      <td>0.615685</td>\n",
       "      <td>0.607773</td>\n",
       "      <td>0.444171</td>\n",
       "      <td>0.627817</td>\n",
       "      <td>0.626808</td>\n",
       "      <td>0.625128</td>\n",
       "      <td>0.622779</td>\n",
       "      <td>0.619763</td>\n",
       "      <td>0.616083</td>\n",
       "      <td>0.611744</td>\n",
       "      <td>0.606749</td>\n",
       "      <td>0.601105</td>\n",
       "      <td>0.594817</td>\n",
       "      <td>0.587892</td>\n",
       "      <td>0.580338</td>\n",
       "      <td>0.454504</td>\n",
       "      <td>0.642422</td>\n",
       "      <td>0.641390</td>\n",
       "      <td>0.639671</td>\n",
       "      <td>0.637267</td>\n",
       "      <td>0.634181</td>\n",
       "      <td>0.630416</td>\n",
       "      <td>0.625975</td>\n",
       "      <td>0.620864</td>\n",
       "      <td>0.615089</td>\n",
       "      <td>0.608655</td>\n",
       "      <td>0.601569</td>\n",
       "      <td>0.593838</td>\n",
       "      <td>0.395086</td>\n",
       "      <td>-0.200571</td>\n",
       "      <td>0.405282</td>\n",
       "      <td>0.501933</td>\n",
       "      <td>-0.073767</td>\n",
       "      <td>0.223811</td>\n",
       "      <td>11.51220</td>\n",
       "      <td>b'1650'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.62912</td>\n",
       "      <td>-3.67598</td>\n",
       "      <td>-1.71978</td>\n",
       "      <td>70.0000</td>\n",
       "      <td>65.3333</td>\n",
       "      <td>71.8519</td>\n",
       "      <td>2.97859</td>\n",
       "      <td>2.15444</td>\n",
       "      <td>3.16653</td>\n",
       "      <td>0.255185</td>\n",
       "      <td>0.193401</td>\n",
       "      <td>0.289781</td>\n",
       "      <td>0.505158</td>\n",
       "      <td>0.439773</td>\n",
       "      <td>0.538313</td>\n",
       "      <td>0.437150</td>\n",
       "      <td>0.617892</td>\n",
       "      <td>0.616899</td>\n",
       "      <td>0.615246</td>\n",
       "      <td>0.612934</td>\n",
       "      <td>0.609965</td>\n",
       "      <td>0.606344</td>\n",
       "      <td>0.602073</td>\n",
       "      <td>0.597157</td>\n",
       "      <td>0.591602</td>\n",
       "      <td>0.585414</td>\n",
       "      <td>0.578598</td>\n",
       "      <td>0.571163</td>\n",
       "      <td>0.389856</td>\n",
       "      <td>0.551044</td>\n",
       "      <td>0.550159</td>\n",
       "      <td>0.548684</td>\n",
       "      <td>0.546622</td>\n",
       "      <td>0.543975</td>\n",
       "      <td>0.540745</td>\n",
       "      <td>0.536937</td>\n",
       "      <td>0.532553</td>\n",
       "      <td>0.527599</td>\n",
       "      <td>0.522080</td>\n",
       "      <td>0.516002</td>\n",
       "      <td>0.509371</td>\n",
       "      <td>0.429256</td>\n",
       "      <td>0.606734</td>\n",
       "      <td>0.605760</td>\n",
       "      <td>0.604136</td>\n",
       "      <td>0.601866</td>\n",
       "      <td>0.598951</td>\n",
       "      <td>0.595395</td>\n",
       "      <td>0.591201</td>\n",
       "      <td>0.586374</td>\n",
       "      <td>0.580920</td>\n",
       "      <td>0.574843</td>\n",
       "      <td>0.568151</td>\n",
       "      <td>0.560850</td>\n",
       "      <td>0.794411</td>\n",
       "      <td>0.366282</td>\n",
       "      <td>0.108550</td>\n",
       "      <td>0.235529</td>\n",
       "      <td>0.026102</td>\n",
       "      <td>-0.366805</td>\n",
       "      <td>10.66480</td>\n",
       "      <td>b'1650'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.41993</td>\n",
       "      <td>-3.07394</td>\n",
       "      <td>-2.68363</td>\n",
       "      <td>83.0435</td>\n",
       "      <td>67.2414</td>\n",
       "      <td>79.5455</td>\n",
       "      <td>2.56174</td>\n",
       "      <td>1.71211</td>\n",
       "      <td>2.75633</td>\n",
       "      <td>0.221399</td>\n",
       "      <td>0.152390</td>\n",
       "      <td>0.245360</td>\n",
       "      <td>0.470530</td>\n",
       "      <td>0.390372</td>\n",
       "      <td>0.495338</td>\n",
       "      <td>0.413661</td>\n",
       "      <td>0.584691</td>\n",
       "      <td>0.583752</td>\n",
       "      <td>0.582188</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.577191</td>\n",
       "      <td>0.573764</td>\n",
       "      <td>0.569723</td>\n",
       "      <td>0.565071</td>\n",
       "      <td>0.559814</td>\n",
       "      <td>0.553958</td>\n",
       "      <td>0.547509</td>\n",
       "      <td>0.540474</td>\n",
       "      <td>0.331764</td>\n",
       "      <td>0.468933</td>\n",
       "      <td>0.468180</td>\n",
       "      <td>0.466925</td>\n",
       "      <td>0.465171</td>\n",
       "      <td>0.462918</td>\n",
       "      <td>0.460169</td>\n",
       "      <td>0.456928</td>\n",
       "      <td>0.453197</td>\n",
       "      <td>0.448982</td>\n",
       "      <td>0.444285</td>\n",
       "      <td>0.439113</td>\n",
       "      <td>0.433470</td>\n",
       "      <td>0.396997</td>\n",
       "      <td>0.561138</td>\n",
       "      <td>0.560237</td>\n",
       "      <td>0.558735</td>\n",
       "      <td>0.556636</td>\n",
       "      <td>0.553940</td>\n",
       "      <td>0.550651</td>\n",
       "      <td>0.546772</td>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.537263</td>\n",
       "      <td>0.531643</td>\n",
       "      <td>0.525454</td>\n",
       "      <td>0.518702</td>\n",
       "      <td>0.848597</td>\n",
       "      <td>0.559720</td>\n",
       "      <td>0.454855</td>\n",
       "      <td>0.405486</td>\n",
       "      <td>-0.049683</td>\n",
       "      <td>-0.101471</td>\n",
       "      <td>10.11240</td>\n",
       "      <td>b'1650'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.95552</td>\n",
       "      <td>-2.67376</td>\n",
       "      <td>-1.65992</td>\n",
       "      <td>70.3704</td>\n",
       "      <td>76.2500</td>\n",
       "      <td>71.5385</td>\n",
       "      <td>2.65143</td>\n",
       "      <td>1.86928</td>\n",
       "      <td>2.51211</td>\n",
       "      <td>0.230854</td>\n",
       "      <td>0.158261</td>\n",
       "      <td>0.228532</td>\n",
       "      <td>0.480472</td>\n",
       "      <td>0.397820</td>\n",
       "      <td>0.478050</td>\n",
       "      <td>0.424584</td>\n",
       "      <td>0.600131</td>\n",
       "      <td>0.599167</td>\n",
       "      <td>0.597562</td>\n",
       "      <td>0.595316</td>\n",
       "      <td>0.592433</td>\n",
       "      <td>0.588915</td>\n",
       "      <td>0.584767</td>\n",
       "      <td>0.579993</td>\n",
       "      <td>0.574598</td>\n",
       "      <td>0.568587</td>\n",
       "      <td>0.561967</td>\n",
       "      <td>0.554746</td>\n",
       "      <td>0.340917</td>\n",
       "      <td>0.481871</td>\n",
       "      <td>0.481097</td>\n",
       "      <td>0.479807</td>\n",
       "      <td>0.478004</td>\n",
       "      <td>0.475689</td>\n",
       "      <td>0.472865</td>\n",
       "      <td>0.469534</td>\n",
       "      <td>0.465701</td>\n",
       "      <td>0.461369</td>\n",
       "      <td>0.456542</td>\n",
       "      <td>0.451227</td>\n",
       "      <td>0.445429</td>\n",
       "      <td>0.394244</td>\n",
       "      <td>0.557247</td>\n",
       "      <td>0.556352</td>\n",
       "      <td>0.554861</td>\n",
       "      <td>0.552775</td>\n",
       "      <td>0.550098</td>\n",
       "      <td>0.546832</td>\n",
       "      <td>0.542981</td>\n",
       "      <td>0.538547</td>\n",
       "      <td>0.533538</td>\n",
       "      <td>0.527956</td>\n",
       "      <td>0.521810</td>\n",
       "      <td>0.515105</td>\n",
       "      <td>0.752024</td>\n",
       "      <td>0.515116</td>\n",
       "      <td>0.217559</td>\n",
       "      <td>0.143717</td>\n",
       "      <td>0.281892</td>\n",
       "      <td>-0.232531</td>\n",
       "      <td>10.19920</td>\n",
       "      <td>b'1650'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-8.60716</td>\n",
       "      <td>-2.40619</td>\n",
       "      <td>-2.52186</td>\n",
       "      <td>101.0530</td>\n",
       "      <td>77.3913</td>\n",
       "      <td>105.0000</td>\n",
       "      <td>2.57757</td>\n",
       "      <td>1.22835</td>\n",
       "      <td>2.00075</td>\n",
       "      <td>0.217810</td>\n",
       "      <td>0.113445</td>\n",
       "      <td>0.185843</td>\n",
       "      <td>0.466701</td>\n",
       "      <td>0.336816</td>\n",
       "      <td>0.431095</td>\n",
       "      <td>0.384544</td>\n",
       "      <td>0.543536</td>\n",
       "      <td>0.542662</td>\n",
       "      <td>0.541208</td>\n",
       "      <td>0.539174</td>\n",
       "      <td>0.536563</td>\n",
       "      <td>0.533377</td>\n",
       "      <td>0.529620</td>\n",
       "      <td>0.525296</td>\n",
       "      <td>0.520410</td>\n",
       "      <td>0.514966</td>\n",
       "      <td>0.508971</td>\n",
       "      <td>0.502430</td>\n",
       "      <td>0.303598</td>\n",
       "      <td>0.429122</td>\n",
       "      <td>0.428433</td>\n",
       "      <td>0.427285</td>\n",
       "      <td>0.425679</td>\n",
       "      <td>0.423617</td>\n",
       "      <td>0.421102</td>\n",
       "      <td>0.418136</td>\n",
       "      <td>0.414722</td>\n",
       "      <td>0.410864</td>\n",
       "      <td>0.406567</td>\n",
       "      <td>0.401833</td>\n",
       "      <td>0.396670</td>\n",
       "      <td>0.373903</td>\n",
       "      <td>0.528495</td>\n",
       "      <td>0.527646</td>\n",
       "      <td>0.526232</td>\n",
       "      <td>0.524254</td>\n",
       "      <td>0.521715</td>\n",
       "      <td>0.518618</td>\n",
       "      <td>0.514965</td>\n",
       "      <td>0.510760</td>\n",
       "      <td>0.506009</td>\n",
       "      <td>0.500716</td>\n",
       "      <td>0.494887</td>\n",
       "      <td>0.488527</td>\n",
       "      <td>0.851431</td>\n",
       "      <td>0.679247</td>\n",
       "      <td>0.392689</td>\n",
       "      <td>0.364159</td>\n",
       "      <td>0.112605</td>\n",
       "      <td>-0.458078</td>\n",
       "      <td>9.78553</td>\n",
       "      <td>b'1650'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTIVITY     X0     X1     X2     X3     X4    X5   X6   X7   X8   X9  \\\n",
       "0         0  0.230  0.235  0.385  0.085  0.055  0.01  0.0  0.0  0.0  0.0   \n",
       "1         0  0.975  0.020  0.005  0.000  0.000  0.00  0.0  0.0  0.0  0.0   \n",
       "2         0  1.000  0.000  0.000  0.000  0.000  0.00  0.0  0.0  0.0  0.0   \n",
       "3         0  0.995  0.005  0.000  0.000  0.000  0.00  0.0  0.0  0.0  0.0   \n",
       "4         0  0.990  0.010  0.000  0.000  0.000  0.00  0.0  0.0  0.0  0.0   \n",
       "\n",
       "      Y0     Y1     Y2     Y3     Y4    Y5    Y6   Y7   Y8   Y9     Z0     Z1  \\\n",
       "0  0.170  0.030  0.085  0.360  0.275  0.07  0.01  0.0  0.0  0.0  0.040  0.050   \n",
       "1  0.660  0.255  0.075  0.005  0.005  0.00  0.00  0.0  0.0  0.0  0.370  0.280   \n",
       "2  0.555  0.415  0.030  0.000  0.000  0.00  0.00  0.0  0.0  0.0  0.440  0.360   \n",
       "3  0.500  0.400  0.100  0.000  0.000  0.00  0.00  0.0  0.0  0.0  0.330  0.350   \n",
       "4  0.380  0.580  0.040  0.000  0.000  0.00  0.00  0.0  0.0  0.0  0.485  0.365   \n",
       "\n",
       "      Z2     Z3     Z4     Z5    Z6     Z7    Z8    Z9     XAVG     YAVG  \\\n",
       "0  0.035  0.090  0.315  0.205  0.11  0.105  0.03  0.02 -1.29421  2.39763   \n",
       "1  0.225  0.085  0.040  0.000  0.00  0.000  0.00  0.00 -8.62912 -3.67598   \n",
       "2  0.150  0.045  0.005  0.000  0.00  0.000  0.00  0.00 -8.41993 -3.07394   \n",
       "3  0.240  0.075  0.005  0.000  0.00  0.000  0.00  0.00 -8.95552 -2.67376   \n",
       "4  0.115  0.025  0.010  0.000  0.00  0.000  0.00  0.00 -8.60716 -2.40619   \n",
       "\n",
       "      ZAVG     XPEAK    YPEAK     ZPEAK  XABSOLDEV  YABSOLDEV  ZABSOLDEV  \\\n",
       "0  7.43651   86.3636  89.5238   71.4815    3.79717    4.20119    3.60697   \n",
       "1 -1.71978   70.0000  65.3333   71.8519    2.97859    2.15444    3.16653   \n",
       "2 -2.68363   83.0435  67.2414   79.5455    2.56174    1.71211    2.75633   \n",
       "3 -1.65992   70.3704  76.2500   71.5385    2.65143    1.86928    2.51211   \n",
       "4 -2.52186  101.0530  77.3913  105.0000    2.57757    1.22835    2.00075   \n",
       "\n",
       "   XSTANDDEV  YSTANDDEV  ZSTANDDEV      XVAR      YVAR      ZVAR    XMFCC0  \\\n",
       "0   0.466331   0.458116   0.347447  0.682884  0.676843  0.589446  0.465170   \n",
       "1   0.255185   0.193401   0.289781  0.505158  0.439773  0.538313  0.437150   \n",
       "2   0.221399   0.152390   0.245360  0.470530  0.390372  0.495338  0.413661   \n",
       "3   0.230854   0.158261   0.228532  0.480472  0.397820  0.478050  0.424584   \n",
       "4   0.217810   0.113445   0.185843  0.466701  0.336816  0.431095  0.384544   \n",
       "\n",
       "     XMFCC1    XMFCC2    XMFCC3    XMFCC4    XMFCC5    XMFCC6    XMFCC7  \\\n",
       "0  0.657497  0.656441  0.654681  0.652221  0.649062  0.645209  0.640664   \n",
       "1  0.617892  0.616899  0.615246  0.612934  0.609965  0.606344  0.602073   \n",
       "2  0.584691  0.583752  0.582188  0.580000  0.577191  0.573764  0.569723   \n",
       "3  0.600131  0.599167  0.597562  0.595316  0.592433  0.588915  0.584767   \n",
       "4  0.543536  0.542662  0.541208  0.539174  0.536563  0.533377  0.529620   \n",
       "\n",
       "     XMFCC8    XMFCC9   XMFCC10   XMFCC11   XMFCC12    YMFCC0    YMFCC1  \\\n",
       "0  0.635433  0.629522  0.622937  0.615685  0.607773  0.444171  0.627817   \n",
       "1  0.597157  0.591602  0.585414  0.578598  0.571163  0.389856  0.551044   \n",
       "2  0.565071  0.559814  0.553958  0.547509  0.540474  0.331764  0.468933   \n",
       "3  0.579993  0.574598  0.568587  0.561967  0.554746  0.340917  0.481871   \n",
       "4  0.525296  0.520410  0.514966  0.508971  0.502430  0.303598  0.429122   \n",
       "\n",
       "     YMFCC2    YMFCC3    YMFCC4    YMFCC5    YMFCC6    YMFCC7    YMFCC8  \\\n",
       "0  0.626808  0.625128  0.622779  0.619763  0.616083  0.611744  0.606749   \n",
       "1  0.550159  0.548684  0.546622  0.543975  0.540745  0.536937  0.532553   \n",
       "2  0.468180  0.466925  0.465171  0.462918  0.460169  0.456928  0.453197   \n",
       "3  0.481097  0.479807  0.478004  0.475689  0.472865  0.469534  0.465701   \n",
       "4  0.428433  0.427285  0.425679  0.423617  0.421102  0.418136  0.414722   \n",
       "\n",
       "     YMFCC9   YMFCC10   YMFCC11   YMFCC12    ZMFCC0    ZMFCC1    ZMFCC2  \\\n",
       "0  0.601105  0.594817  0.587892  0.580338  0.454504  0.642422  0.641390   \n",
       "1  0.527599  0.522080  0.516002  0.509371  0.429256  0.606734  0.605760   \n",
       "2  0.448982  0.444285  0.439113  0.433470  0.396997  0.561138  0.560237   \n",
       "3  0.461369  0.456542  0.451227  0.445429  0.394244  0.557247  0.556352   \n",
       "4  0.410864  0.406567  0.401833  0.396670  0.373903  0.528495  0.527646   \n",
       "\n",
       "     ZMFCC3    ZMFCC4    ZMFCC5    ZMFCC6    ZMFCC7    ZMFCC8    ZMFCC9  \\\n",
       "0  0.639671  0.637267  0.634181  0.630416  0.625975  0.620864  0.615089   \n",
       "1  0.604136  0.601866  0.598951  0.595395  0.591201  0.586374  0.580920   \n",
       "2  0.558735  0.556636  0.553940  0.550651  0.546772  0.542308  0.537263   \n",
       "3  0.554861  0.552775  0.550098  0.546832  0.542981  0.538547  0.533538   \n",
       "4  0.526232  0.524254  0.521715  0.518618  0.514965  0.510760  0.506009   \n",
       "\n",
       "    ZMFCC10   ZMFCC11   ZMFCC12     XYCOS     XZCOS     YZCOS     XYCOR  \\\n",
       "0  0.608655  0.601569  0.593838  0.395086 -0.200571  0.405282  0.501933   \n",
       "1  0.574843  0.568151  0.560850  0.794411  0.366282  0.108550  0.235529   \n",
       "2  0.531643  0.525454  0.518702  0.848597  0.559720  0.454855  0.405486   \n",
       "3  0.527956  0.521810  0.515105  0.752024  0.515116  0.217559  0.143717   \n",
       "4  0.500716  0.494887  0.488527  0.851431  0.679247  0.392689  0.364159   \n",
       "\n",
       "      XZCOR     YZCOR  RESULTANT    class  \n",
       "0 -0.073767  0.223811   11.51220  b'1650'  \n",
       "1  0.026102 -0.366805   10.66480  b'1650'  \n",
       "2 -0.049683 -0.101471   10.11240  b'1650'  \n",
       "3  0.281892 -0.232531   10.19920  b'1650'  \n",
       "4  0.112605 -0.458078    9.78553  b'1650'  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "phone_accel_df['ACTIVITY'] = labelencoder.fit_transform(phone_accel_df['ACTIVITY'])\n",
    "phone_accel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 23074 entries, 0 to 320\n",
      "Data columns (total 92 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ACTIVITY   23074 non-null  int32  \n",
      " 1   X0         23074 non-null  float64\n",
      " 2   X1         23074 non-null  float64\n",
      " 3   X2         23074 non-null  float64\n",
      " 4   X3         23074 non-null  float64\n",
      " 5   X4         23074 non-null  float64\n",
      " 6   X5         23074 non-null  float64\n",
      " 7   X6         23074 non-null  float64\n",
      " 8   X7         23074 non-null  float64\n",
      " 9   X8         23074 non-null  float64\n",
      " 10  X9         23074 non-null  float64\n",
      " 11  Y0         23074 non-null  float64\n",
      " 12  Y1         23074 non-null  float64\n",
      " 13  Y2         23074 non-null  float64\n",
      " 14  Y3         23074 non-null  float64\n",
      " 15  Y4         23074 non-null  float64\n",
      " 16  Y5         23074 non-null  float64\n",
      " 17  Y6         23074 non-null  float64\n",
      " 18  Y7         23074 non-null  float64\n",
      " 19  Y8         23074 non-null  float64\n",
      " 20  Y9         23074 non-null  float64\n",
      " 21  Z0         23074 non-null  float64\n",
      " 22  Z1         23074 non-null  float64\n",
      " 23  Z2         23074 non-null  float64\n",
      " 24  Z3         23074 non-null  float64\n",
      " 25  Z4         23074 non-null  float64\n",
      " 26  Z5         23074 non-null  float64\n",
      " 27  Z6         23074 non-null  float64\n",
      " 28  Z7         23074 non-null  float64\n",
      " 29  Z8         23074 non-null  float64\n",
      " 30  Z9         23074 non-null  float64\n",
      " 31  XAVG       23074 non-null  float64\n",
      " 32  YAVG       23074 non-null  float64\n",
      " 33  ZAVG       23074 non-null  float64\n",
      " 34  XPEAK      23074 non-null  float64\n",
      " 35  YPEAK      23074 non-null  float64\n",
      " 36  ZPEAK      23074 non-null  float64\n",
      " 37  XABSOLDEV  23074 non-null  float64\n",
      " 38  YABSOLDEV  23074 non-null  float64\n",
      " 39  ZABSOLDEV  23074 non-null  float64\n",
      " 40  XSTANDDEV  23074 non-null  float64\n",
      " 41  YSTANDDEV  23074 non-null  float64\n",
      " 42  ZSTANDDEV  23074 non-null  float64\n",
      " 43  XVAR       23074 non-null  float64\n",
      " 44  YVAR       23074 non-null  float64\n",
      " 45  ZVAR       23074 non-null  float64\n",
      " 46  XMFCC0     23074 non-null  float64\n",
      " 47  XMFCC1     23074 non-null  float64\n",
      " 48  XMFCC2     23074 non-null  float64\n",
      " 49  XMFCC3     23074 non-null  float64\n",
      " 50  XMFCC4     23074 non-null  float64\n",
      " 51  XMFCC5     23074 non-null  float64\n",
      " 52  XMFCC6     23074 non-null  float64\n",
      " 53  XMFCC7     23074 non-null  float64\n",
      " 54  XMFCC8     23074 non-null  float64\n",
      " 55  XMFCC9     23074 non-null  float64\n",
      " 56  XMFCC10    23074 non-null  float64\n",
      " 57  XMFCC11    23074 non-null  float64\n",
      " 58  XMFCC12    23074 non-null  float64\n",
      " 59  YMFCC0     23074 non-null  float64\n",
      " 60  YMFCC1     23074 non-null  float64\n",
      " 61  YMFCC2     23074 non-null  float64\n",
      " 62  YMFCC3     23074 non-null  float64\n",
      " 63  YMFCC4     23074 non-null  float64\n",
      " 64  YMFCC5     23074 non-null  float64\n",
      " 65  YMFCC6     23074 non-null  float64\n",
      " 66  YMFCC7     23074 non-null  float64\n",
      " 67  YMFCC8     23074 non-null  float64\n",
      " 68  YMFCC9     23074 non-null  float64\n",
      " 69  YMFCC10    23074 non-null  float64\n",
      " 70  YMFCC11    23074 non-null  float64\n",
      " 71  YMFCC12    23074 non-null  float64\n",
      " 72  ZMFCC0     23074 non-null  float64\n",
      " 73  ZMFCC1     23074 non-null  float64\n",
      " 74  ZMFCC2     23074 non-null  float64\n",
      " 75  ZMFCC3     23074 non-null  float64\n",
      " 76  ZMFCC4     23074 non-null  float64\n",
      " 77  ZMFCC5     23074 non-null  float64\n",
      " 78  ZMFCC6     23074 non-null  float64\n",
      " 79  ZMFCC7     23074 non-null  float64\n",
      " 80  ZMFCC8     23074 non-null  float64\n",
      " 81  ZMFCC9     23074 non-null  float64\n",
      " 82  ZMFCC10    23074 non-null  float64\n",
      " 83  ZMFCC11    23074 non-null  float64\n",
      " 84  ZMFCC12    23074 non-null  float64\n",
      " 85  XYCOS      23074 non-null  float64\n",
      " 86  XZCOS      23074 non-null  float64\n",
      " 87  YZCOS      23074 non-null  float64\n",
      " 88  XYCOR      23074 non-null  float64\n",
      " 89  XZCOR      23074 non-null  float64\n",
      " 90  YZCOR      23074 non-null  float64\n",
      " 91  RESULTANT  23074 non-null  float64\n",
      "dtypes: float64(91), int32(1)\n",
      "memory usage: 16.3 MB\n"
     ]
    }
   ],
   "source": [
    "phone_accel_df.pop('class')\n",
    "phone_accel_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y3</th>\n",
       "      <th>Y4</th>\n",
       "      <th>Y5</th>\n",
       "      <th>Y6</th>\n",
       "      <th>Y7</th>\n",
       "      <th>Y8</th>\n",
       "      <th>Y9</th>\n",
       "      <th>Z0</th>\n",
       "      <th>Z1</th>\n",
       "      <th>Z2</th>\n",
       "      <th>Z3</th>\n",
       "      <th>Z4</th>\n",
       "      <th>Z5</th>\n",
       "      <th>Z6</th>\n",
       "      <th>Z7</th>\n",
       "      <th>Z8</th>\n",
       "      <th>Z9</th>\n",
       "      <th>XAVG</th>\n",
       "      <th>YAVG</th>\n",
       "      <th>ZAVG</th>\n",
       "      <th>XPEAK</th>\n",
       "      <th>YPEAK</th>\n",
       "      <th>ZPEAK</th>\n",
       "      <th>XABSOLDEV</th>\n",
       "      <th>YABSOLDEV</th>\n",
       "      <th>ZABSOLDEV</th>\n",
       "      <th>XSTANDDEV</th>\n",
       "      <th>YSTANDDEV</th>\n",
       "      <th>ZSTANDDEV</th>\n",
       "      <th>XVAR</th>\n",
       "      <th>YVAR</th>\n",
       "      <th>ZVAR</th>\n",
       "      <th>XMFCC0</th>\n",
       "      <th>XMFCC1</th>\n",
       "      <th>XMFCC2</th>\n",
       "      <th>XMFCC3</th>\n",
       "      <th>XMFCC4</th>\n",
       "      <th>XMFCC5</th>\n",
       "      <th>XMFCC6</th>\n",
       "      <th>XMFCC7</th>\n",
       "      <th>XMFCC8</th>\n",
       "      <th>XMFCC9</th>\n",
       "      <th>XMFCC10</th>\n",
       "      <th>XMFCC11</th>\n",
       "      <th>XMFCC12</th>\n",
       "      <th>YMFCC0</th>\n",
       "      <th>YMFCC1</th>\n",
       "      <th>YMFCC2</th>\n",
       "      <th>YMFCC3</th>\n",
       "      <th>YMFCC4</th>\n",
       "      <th>YMFCC5</th>\n",
       "      <th>YMFCC6</th>\n",
       "      <th>YMFCC7</th>\n",
       "      <th>YMFCC8</th>\n",
       "      <th>YMFCC9</th>\n",
       "      <th>YMFCC10</th>\n",
       "      <th>YMFCC11</th>\n",
       "      <th>YMFCC12</th>\n",
       "      <th>ZMFCC0</th>\n",
       "      <th>ZMFCC1</th>\n",
       "      <th>ZMFCC2</th>\n",
       "      <th>ZMFCC3</th>\n",
       "      <th>ZMFCC4</th>\n",
       "      <th>ZMFCC5</th>\n",
       "      <th>ZMFCC6</th>\n",
       "      <th>ZMFCC7</th>\n",
       "      <th>ZMFCC8</th>\n",
       "      <th>ZMFCC9</th>\n",
       "      <th>ZMFCC10</th>\n",
       "      <th>ZMFCC11</th>\n",
       "      <th>ZMFCC12</th>\n",
       "      <th>XYCOS</th>\n",
       "      <th>XZCOS</th>\n",
       "      <th>YZCOS</th>\n",
       "      <th>XYCOR</th>\n",
       "      <th>XZCOR</th>\n",
       "      <th>YZCOR</th>\n",
       "      <th>RESULTANT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.151996</td>\n",
       "      <td>9.794690</td>\n",
       "      <td>-1.258880</td>\n",
       "      <td>36.4151</td>\n",
       "      <td>32.2951</td>\n",
       "      <td>33.0508</td>\n",
       "      <td>0.062255</td>\n",
       "      <td>0.022872</td>\n",
       "      <td>0.049490</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.075471</td>\n",
       "      <td>0.045672</td>\n",
       "      <td>0.068926</td>\n",
       "      <td>-0.104081</td>\n",
       "      <td>-0.147114</td>\n",
       "      <td>-0.146878</td>\n",
       "      <td>-0.146484</td>\n",
       "      <td>-0.145934</td>\n",
       "      <td>-0.145227</td>\n",
       "      <td>-0.144365</td>\n",
       "      <td>-0.143348</td>\n",
       "      <td>-0.142178</td>\n",
       "      <td>-0.140855</td>\n",
       "      <td>-0.139382</td>\n",
       "      <td>-0.137759</td>\n",
       "      <td>-0.135989</td>\n",
       "      <td>0.343206</td>\n",
       "      <td>0.485107</td>\n",
       "      <td>0.484328</td>\n",
       "      <td>0.483030</td>\n",
       "      <td>0.481215</td>\n",
       "      <td>0.478884</td>\n",
       "      <td>0.476041</td>\n",
       "      <td>0.472688</td>\n",
       "      <td>0.468828</td>\n",
       "      <td>0.464467</td>\n",
       "      <td>0.459609</td>\n",
       "      <td>0.454258</td>\n",
       "      <td>0.448421</td>\n",
       "      <td>0.057287</td>\n",
       "      <td>0.080973</td>\n",
       "      <td>0.080842</td>\n",
       "      <td>0.080626</td>\n",
       "      <td>0.080323</td>\n",
       "      <td>0.079934</td>\n",
       "      <td>0.079459</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.078255</td>\n",
       "      <td>0.077527</td>\n",
       "      <td>0.076717</td>\n",
       "      <td>0.075823</td>\n",
       "      <td>0.074849</td>\n",
       "      <td>-0.883652</td>\n",
       "      <td>0.891302</td>\n",
       "      <td>-0.998565</td>\n",
       "      <td>-0.049950</td>\n",
       "      <td>0.359520</td>\n",
       "      <td>0.054988</td>\n",
       "      <td>9.87698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.179840</td>\n",
       "      <td>3.448410</td>\n",
       "      <td>6.735140</td>\n",
       "      <td>51.3158</td>\n",
       "      <td>52.7778</td>\n",
       "      <td>33.6207</td>\n",
       "      <td>0.127589</td>\n",
       "      <td>0.102453</td>\n",
       "      <td>0.048898</td>\n",
       "      <td>0.011317</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.106380</td>\n",
       "      <td>0.093901</td>\n",
       "      <td>0.069823</td>\n",
       "      <td>0.255453</td>\n",
       "      <td>0.361072</td>\n",
       "      <td>0.360492</td>\n",
       "      <td>0.359526</td>\n",
       "      <td>0.358175</td>\n",
       "      <td>0.356440</td>\n",
       "      <td>0.354324</td>\n",
       "      <td>0.351828</td>\n",
       "      <td>0.348956</td>\n",
       "      <td>0.345710</td>\n",
       "      <td>0.342093</td>\n",
       "      <td>0.338111</td>\n",
       "      <td>0.333766</td>\n",
       "      <td>0.196979</td>\n",
       "      <td>0.278421</td>\n",
       "      <td>0.277974</td>\n",
       "      <td>0.277229</td>\n",
       "      <td>0.276187</td>\n",
       "      <td>0.274850</td>\n",
       "      <td>0.273218</td>\n",
       "      <td>0.271293</td>\n",
       "      <td>0.269078</td>\n",
       "      <td>0.266575</td>\n",
       "      <td>0.263787</td>\n",
       "      <td>0.260716</td>\n",
       "      <td>0.257365</td>\n",
       "      <td>0.288686</td>\n",
       "      <td>0.408046</td>\n",
       "      <td>0.407390</td>\n",
       "      <td>0.406298</td>\n",
       "      <td>0.404771</td>\n",
       "      <td>0.402811</td>\n",
       "      <td>0.400420</td>\n",
       "      <td>0.397599</td>\n",
       "      <td>0.394353</td>\n",
       "      <td>0.390685</td>\n",
       "      <td>0.386598</td>\n",
       "      <td>0.382097</td>\n",
       "      <td>0.377187</td>\n",
       "      <td>0.998417</td>\n",
       "      <td>0.999308</td>\n",
       "      <td>0.999261</td>\n",
       "      <td>-0.406369</td>\n",
       "      <td>-0.514073</td>\n",
       "      <td>-0.090117</td>\n",
       "      <td>9.17202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>12</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.696940</td>\n",
       "      <td>-8.969780</td>\n",
       "      <td>2.418180</td>\n",
       "      <td>76.2500</td>\n",
       "      <td>65.5172</td>\n",
       "      <td>60.3226</td>\n",
       "      <td>1.347730</td>\n",
       "      <td>0.723042</td>\n",
       "      <td>1.144910</td>\n",
       "      <td>0.125610</td>\n",
       "      <td>0.086476</td>\n",
       "      <td>0.104627</td>\n",
       "      <td>0.354415</td>\n",
       "      <td>0.294069</td>\n",
       "      <td>0.323461</td>\n",
       "      <td>0.301150</td>\n",
       "      <td>0.425662</td>\n",
       "      <td>0.424978</td>\n",
       "      <td>0.423839</td>\n",
       "      <td>0.422247</td>\n",
       "      <td>0.420202</td>\n",
       "      <td>0.417707</td>\n",
       "      <td>0.414765</td>\n",
       "      <td>0.411378</td>\n",
       "      <td>0.407551</td>\n",
       "      <td>0.403288</td>\n",
       "      <td>0.398593</td>\n",
       "      <td>0.393471</td>\n",
       "      <td>0.372889</td>\n",
       "      <td>0.527063</td>\n",
       "      <td>0.526216</td>\n",
       "      <td>0.524806</td>\n",
       "      <td>0.522833</td>\n",
       "      <td>0.520301</td>\n",
       "      <td>0.517212</td>\n",
       "      <td>0.513569</td>\n",
       "      <td>0.509376</td>\n",
       "      <td>0.504638</td>\n",
       "      <td>0.499359</td>\n",
       "      <td>0.493545</td>\n",
       "      <td>0.487203</td>\n",
       "      <td>0.269238</td>\n",
       "      <td>0.380556</td>\n",
       "      <td>0.379944</td>\n",
       "      <td>0.378926</td>\n",
       "      <td>0.377502</td>\n",
       "      <td>0.375674</td>\n",
       "      <td>0.373444</td>\n",
       "      <td>0.370813</td>\n",
       "      <td>0.367786</td>\n",
       "      <td>0.364364</td>\n",
       "      <td>0.360553</td>\n",
       "      <td>0.356355</td>\n",
       "      <td>0.351776</td>\n",
       "      <td>-0.653931</td>\n",
       "      <td>0.566059</td>\n",
       "      <td>-0.839512</td>\n",
       "      <td>0.312109</td>\n",
       "      <td>-0.061321</td>\n",
       "      <td>0.080221</td>\n",
       "      <td>9.72761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.506590</td>\n",
       "      <td>1.445730</td>\n",
       "      <td>4.584040</td>\n",
       "      <td>36.7925</td>\n",
       "      <td>30.7937</td>\n",
       "      <td>36.0377</td>\n",
       "      <td>0.074607</td>\n",
       "      <td>0.048297</td>\n",
       "      <td>0.117841</td>\n",
       "      <td>0.006716</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.010113</td>\n",
       "      <td>0.081953</td>\n",
       "      <td>0.066689</td>\n",
       "      <td>0.100562</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.456656</td>\n",
       "      <td>0.455922</td>\n",
       "      <td>0.454700</td>\n",
       "      <td>0.452992</td>\n",
       "      <td>0.450798</td>\n",
       "      <td>0.448121</td>\n",
       "      <td>0.444965</td>\n",
       "      <td>0.441332</td>\n",
       "      <td>0.437226</td>\n",
       "      <td>0.432653</td>\n",
       "      <td>0.427616</td>\n",
       "      <td>0.422121</td>\n",
       "      <td>0.073560</td>\n",
       "      <td>0.103974</td>\n",
       "      <td>0.103806</td>\n",
       "      <td>0.103528</td>\n",
       "      <td>0.103139</td>\n",
       "      <td>0.102640</td>\n",
       "      <td>0.102030</td>\n",
       "      <td>0.101312</td>\n",
       "      <td>0.100484</td>\n",
       "      <td>0.099550</td>\n",
       "      <td>0.098508</td>\n",
       "      <td>0.097362</td>\n",
       "      <td>0.096111</td>\n",
       "      <td>0.235690</td>\n",
       "      <td>0.333138</td>\n",
       "      <td>0.332603</td>\n",
       "      <td>0.331711</td>\n",
       "      <td>0.330465</td>\n",
       "      <td>0.328864</td>\n",
       "      <td>0.326912</td>\n",
       "      <td>0.324609</td>\n",
       "      <td>0.321959</td>\n",
       "      <td>0.318964</td>\n",
       "      <td>0.315627</td>\n",
       "      <td>0.311953</td>\n",
       "      <td>0.307944</td>\n",
       "      <td>0.998715</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.999337</td>\n",
       "      <td>-0.572334</td>\n",
       "      <td>-0.885071</td>\n",
       "      <td>0.566669</td>\n",
       "      <td>9.77228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>8</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.873570</td>\n",
       "      <td>4.153160</td>\n",
       "      <td>-6.473260</td>\n",
       "      <td>40.8511</td>\n",
       "      <td>38.2000</td>\n",
       "      <td>35.6364</td>\n",
       "      <td>0.028785</td>\n",
       "      <td>0.047126</td>\n",
       "      <td>0.045386</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.051167</td>\n",
       "      <td>0.063352</td>\n",
       "      <td>0.063329</td>\n",
       "      <td>0.292119</td>\n",
       "      <td>0.412897</td>\n",
       "      <td>0.412234</td>\n",
       "      <td>0.411129</td>\n",
       "      <td>0.409584</td>\n",
       "      <td>0.407600</td>\n",
       "      <td>0.405180</td>\n",
       "      <td>0.402326</td>\n",
       "      <td>0.399042</td>\n",
       "      <td>0.395330</td>\n",
       "      <td>0.391194</td>\n",
       "      <td>0.386640</td>\n",
       "      <td>0.381672</td>\n",
       "      <td>0.217395</td>\n",
       "      <td>0.307278</td>\n",
       "      <td>0.306785</td>\n",
       "      <td>0.305962</td>\n",
       "      <td>0.304813</td>\n",
       "      <td>0.303336</td>\n",
       "      <td>0.301535</td>\n",
       "      <td>0.299411</td>\n",
       "      <td>0.296967</td>\n",
       "      <td>0.294204</td>\n",
       "      <td>0.291127</td>\n",
       "      <td>0.287738</td>\n",
       "      <td>0.284040</td>\n",
       "      <td>0.283667</td>\n",
       "      <td>0.400951</td>\n",
       "      <td>0.400307</td>\n",
       "      <td>0.399234</td>\n",
       "      <td>0.397734</td>\n",
       "      <td>0.395808</td>\n",
       "      <td>0.393458</td>\n",
       "      <td>0.390686</td>\n",
       "      <td>0.387496</td>\n",
       "      <td>0.383892</td>\n",
       "      <td>0.379876</td>\n",
       "      <td>0.375454</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>-0.999910</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>-0.999780</td>\n",
       "      <td>-0.244558</td>\n",
       "      <td>-0.566907</td>\n",
       "      <td>0.738233</td>\n",
       "      <td>10.31530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>17</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.743000</td>\n",
       "      <td>-9.338500</td>\n",
       "      <td>-0.453747</td>\n",
       "      <td>60.6667</td>\n",
       "      <td>45.8140</td>\n",
       "      <td>44.2857</td>\n",
       "      <td>0.431612</td>\n",
       "      <td>0.129284</td>\n",
       "      <td>0.822550</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>0.011332</td>\n",
       "      <td>0.063783</td>\n",
       "      <td>0.188857</td>\n",
       "      <td>0.106451</td>\n",
       "      <td>0.252553</td>\n",
       "      <td>0.194561</td>\n",
       "      <td>0.275004</td>\n",
       "      <td>0.274562</td>\n",
       "      <td>0.273826</td>\n",
       "      <td>0.272797</td>\n",
       "      <td>0.271476</td>\n",
       "      <td>0.269864</td>\n",
       "      <td>0.267963</td>\n",
       "      <td>0.265775</td>\n",
       "      <td>0.263303</td>\n",
       "      <td>0.260549</td>\n",
       "      <td>0.257515</td>\n",
       "      <td>0.254206</td>\n",
       "      <td>0.334093</td>\n",
       "      <td>0.472226</td>\n",
       "      <td>0.471468</td>\n",
       "      <td>0.470204</td>\n",
       "      <td>0.468437</td>\n",
       "      <td>0.466168</td>\n",
       "      <td>0.463401</td>\n",
       "      <td>0.460137</td>\n",
       "      <td>0.456380</td>\n",
       "      <td>0.452134</td>\n",
       "      <td>0.447405</td>\n",
       "      <td>0.442196</td>\n",
       "      <td>0.436514</td>\n",
       "      <td>0.074716</td>\n",
       "      <td>0.105607</td>\n",
       "      <td>0.105438</td>\n",
       "      <td>0.105155</td>\n",
       "      <td>0.104760</td>\n",
       "      <td>0.104253</td>\n",
       "      <td>0.103634</td>\n",
       "      <td>0.102904</td>\n",
       "      <td>0.102063</td>\n",
       "      <td>0.101114</td>\n",
       "      <td>0.100056</td>\n",
       "      <td>0.098891</td>\n",
       "      <td>0.097621</td>\n",
       "      <td>0.980796</td>\n",
       "      <td>0.585169</td>\n",
       "      <td>0.437884</td>\n",
       "      <td>-0.827801</td>\n",
       "      <td>0.886334</td>\n",
       "      <td>-0.745483</td>\n",
       "      <td>9.79916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>5</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.233900</td>\n",
       "      <td>-1.365230</td>\n",
       "      <td>-0.632082</td>\n",
       "      <td>68.2143</td>\n",
       "      <td>86.3636</td>\n",
       "      <td>80.0000</td>\n",
       "      <td>0.221781</td>\n",
       "      <td>0.358104</td>\n",
       "      <td>0.616038</td>\n",
       "      <td>0.023911</td>\n",
       "      <td>0.036584</td>\n",
       "      <td>0.057271</td>\n",
       "      <td>0.154633</td>\n",
       "      <td>0.191270</td>\n",
       "      <td>0.239314</td>\n",
       "      <td>0.340167</td>\n",
       "      <td>0.480812</td>\n",
       "      <td>0.480039</td>\n",
       "      <td>0.478753</td>\n",
       "      <td>0.476954</td>\n",
       "      <td>0.474644</td>\n",
       "      <td>0.471826</td>\n",
       "      <td>0.468502</td>\n",
       "      <td>0.464677</td>\n",
       "      <td>0.460355</td>\n",
       "      <td>0.455539</td>\n",
       "      <td>0.450236</td>\n",
       "      <td>0.444450</td>\n",
       "      <td>0.111671</td>\n",
       "      <td>0.157842</td>\n",
       "      <td>0.157588</td>\n",
       "      <td>0.157166</td>\n",
       "      <td>0.156575</td>\n",
       "      <td>0.155817</td>\n",
       "      <td>0.154892</td>\n",
       "      <td>0.153801</td>\n",
       "      <td>0.152545</td>\n",
       "      <td>0.151126</td>\n",
       "      <td>0.149545</td>\n",
       "      <td>0.147804</td>\n",
       "      <td>0.145905</td>\n",
       "      <td>0.126810</td>\n",
       "      <td>0.179241</td>\n",
       "      <td>0.178953</td>\n",
       "      <td>0.178473</td>\n",
       "      <td>0.177802</td>\n",
       "      <td>0.176941</td>\n",
       "      <td>0.175891</td>\n",
       "      <td>0.174652</td>\n",
       "      <td>0.173226</td>\n",
       "      <td>0.171614</td>\n",
       "      <td>0.169819</td>\n",
       "      <td>0.167842</td>\n",
       "      <td>0.165685</td>\n",
       "      <td>0.928519</td>\n",
       "      <td>0.602343</td>\n",
       "      <td>0.760343</td>\n",
       "      <td>-0.459482</td>\n",
       "      <td>-0.432456</td>\n",
       "      <td>0.662340</td>\n",
       "      <td>9.40674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.901860</td>\n",
       "      <td>8.821500</td>\n",
       "      <td>-1.087800</td>\n",
       "      <td>44.6512</td>\n",
       "      <td>34.7273</td>\n",
       "      <td>32.8070</td>\n",
       "      <td>3.719120</td>\n",
       "      <td>3.060620</td>\n",
       "      <td>2.327160</td>\n",
       "      <td>0.317511</td>\n",
       "      <td>0.271342</td>\n",
       "      <td>0.247547</td>\n",
       "      <td>0.563481</td>\n",
       "      <td>0.520905</td>\n",
       "      <td>0.497541</td>\n",
       "      <td>0.463491</td>\n",
       "      <td>0.655124</td>\n",
       "      <td>0.654072</td>\n",
       "      <td>0.652319</td>\n",
       "      <td>0.649868</td>\n",
       "      <td>0.646720</td>\n",
       "      <td>0.642880</td>\n",
       "      <td>0.638352</td>\n",
       "      <td>0.633140</td>\n",
       "      <td>0.627251</td>\n",
       "      <td>0.620689</td>\n",
       "      <td>0.613463</td>\n",
       "      <td>0.605580</td>\n",
       "      <td>0.467915</td>\n",
       "      <td>0.661378</td>\n",
       "      <td>0.660316</td>\n",
       "      <td>0.658546</td>\n",
       "      <td>0.656071</td>\n",
       "      <td>0.652894</td>\n",
       "      <td>0.649017</td>\n",
       "      <td>0.644446</td>\n",
       "      <td>0.639184</td>\n",
       "      <td>0.633238</td>\n",
       "      <td>0.626614</td>\n",
       "      <td>0.619319</td>\n",
       "      <td>0.611361</td>\n",
       "      <td>0.445445</td>\n",
       "      <td>0.629617</td>\n",
       "      <td>0.628606</td>\n",
       "      <td>0.626921</td>\n",
       "      <td>0.624565</td>\n",
       "      <td>0.621541</td>\n",
       "      <td>0.617850</td>\n",
       "      <td>0.613498</td>\n",
       "      <td>0.608489</td>\n",
       "      <td>0.602829</td>\n",
       "      <td>0.596523</td>\n",
       "      <td>0.589578</td>\n",
       "      <td>0.582002</td>\n",
       "      <td>0.694360</td>\n",
       "      <td>0.036268</td>\n",
       "      <td>-0.291325</td>\n",
       "      <td>0.308493</td>\n",
       "      <td>0.320320</td>\n",
       "      <td>-0.050466</td>\n",
       "      <td>10.97900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.407710</td>\n",
       "      <td>-8.796860</td>\n",
       "      <td>-0.127595</td>\n",
       "      <td>58.7097</td>\n",
       "      <td>88.6364</td>\n",
       "      <td>65.5172</td>\n",
       "      <td>1.209220</td>\n",
       "      <td>1.898260</td>\n",
       "      <td>1.166670</td>\n",
       "      <td>0.106734</td>\n",
       "      <td>0.174358</td>\n",
       "      <td>0.112951</td>\n",
       "      <td>0.326701</td>\n",
       "      <td>0.417562</td>\n",
       "      <td>0.336082</td>\n",
       "      <td>0.285235</td>\n",
       "      <td>0.403168</td>\n",
       "      <td>0.402520</td>\n",
       "      <td>0.401441</td>\n",
       "      <td>0.399933</td>\n",
       "      <td>0.397996</td>\n",
       "      <td>0.395633</td>\n",
       "      <td>0.392846</td>\n",
       "      <td>0.389639</td>\n",
       "      <td>0.386014</td>\n",
       "      <td>0.381976</td>\n",
       "      <td>0.377529</td>\n",
       "      <td>0.372678</td>\n",
       "      <td>0.378622</td>\n",
       "      <td>0.535166</td>\n",
       "      <td>0.534307</td>\n",
       "      <td>0.532875</td>\n",
       "      <td>0.530872</td>\n",
       "      <td>0.528301</td>\n",
       "      <td>0.525164</td>\n",
       "      <td>0.521465</td>\n",
       "      <td>0.517208</td>\n",
       "      <td>0.512397</td>\n",
       "      <td>0.507037</td>\n",
       "      <td>0.501134</td>\n",
       "      <td>0.494694</td>\n",
       "      <td>0.316802</td>\n",
       "      <td>0.447786</td>\n",
       "      <td>0.447067</td>\n",
       "      <td>0.445869</td>\n",
       "      <td>0.444193</td>\n",
       "      <td>0.442042</td>\n",
       "      <td>0.439417</td>\n",
       "      <td>0.436322</td>\n",
       "      <td>0.432760</td>\n",
       "      <td>0.428734</td>\n",
       "      <td>0.424249</td>\n",
       "      <td>0.419310</td>\n",
       "      <td>0.413922</td>\n",
       "      <td>0.796771</td>\n",
       "      <td>0.135824</td>\n",
       "      <td>0.086103</td>\n",
       "      <td>-0.132895</td>\n",
       "      <td>0.129110</td>\n",
       "      <td>0.035064</td>\n",
       "      <td>9.39429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>9</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.261160</td>\n",
       "      <td>-0.603832</td>\n",
       "      <td>6.748650</td>\n",
       "      <td>49.7436</td>\n",
       "      <td>34.6429</td>\n",
       "      <td>50.2703</td>\n",
       "      <td>0.014316</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>0.031875</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.035970</td>\n",
       "      <td>0.022892</td>\n",
       "      <td>0.053569</td>\n",
       "      <td>0.299391</td>\n",
       "      <td>0.423176</td>\n",
       "      <td>0.422497</td>\n",
       "      <td>0.421364</td>\n",
       "      <td>0.419781</td>\n",
       "      <td>0.417748</td>\n",
       "      <td>0.415268</td>\n",
       "      <td>0.412343</td>\n",
       "      <td>0.408976</td>\n",
       "      <td>0.405172</td>\n",
       "      <td>0.400933</td>\n",
       "      <td>0.396266</td>\n",
       "      <td>0.391174</td>\n",
       "      <td>-0.057794</td>\n",
       "      <td>-0.081689</td>\n",
       "      <td>-0.081558</td>\n",
       "      <td>-0.081339</td>\n",
       "      <td>-0.081033</td>\n",
       "      <td>-0.080641</td>\n",
       "      <td>-0.080162</td>\n",
       "      <td>-0.079597</td>\n",
       "      <td>-0.078948</td>\n",
       "      <td>-0.078213</td>\n",
       "      <td>-0.077395</td>\n",
       "      <td>-0.076494</td>\n",
       "      <td>-0.075511</td>\n",
       "      <td>0.289290</td>\n",
       "      <td>0.408899</td>\n",
       "      <td>0.408242</td>\n",
       "      <td>0.407148</td>\n",
       "      <td>0.405618</td>\n",
       "      <td>0.403654</td>\n",
       "      <td>0.401257</td>\n",
       "      <td>0.398431</td>\n",
       "      <td>0.395178</td>\n",
       "      <td>0.391502</td>\n",
       "      <td>0.387406</td>\n",
       "      <td>0.382896</td>\n",
       "      <td>0.377976</td>\n",
       "      <td>-0.999914</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>-0.999927</td>\n",
       "      <td>0.249486</td>\n",
       "      <td>-0.709213</td>\n",
       "      <td>-0.279604</td>\n",
       "      <td>9.93151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ACTIVITY     X0     X1     X2     X3    X4     X5    X6    X7     X8  \\\n",
       "87          4  0.000  0.970  0.030  0.000  0.00  0.000  0.00  0.00  0.000   \n",
       "292        16  0.000  0.000  0.000  0.120  0.88  0.000  0.00  0.00  0.000   \n",
       "560        12  0.030  0.095  0.530  0.335  0.01  0.000  0.00  0.00  0.000   \n",
       "84          3  0.000  0.000  0.000  0.000  0.00  1.000  0.00  0.00  0.000   \n",
       "159         8  1.000  0.000  0.000  0.000  0.00  0.000  0.00  0.00  0.000   \n",
       "518        17  0.655  0.345  0.000  0.000  0.00  0.000  0.00  0.00  0.000   \n",
       "224         5  1.000  0.000  0.000  0.000  0.00  0.000  0.00  0.00  0.000   \n",
       "10          0  0.070  0.155  0.180  0.170  0.20  0.155  0.04  0.02  0.005   \n",
       "113         2  0.455  0.530  0.015  0.000  0.00  0.000  0.00  0.00  0.000   \n",
       "428         9  0.000  0.000  0.000  0.000  1.00  0.000  0.00  0.00  0.000   \n",
       "\n",
       "        X9     Y0     Y1   Y2     Y3     Y4     Y5     Y6    Y7    Y8    Y9  \\\n",
       "87   0.000  0.000  0.000  0.0  0.000  0.000  1.000  0.000  0.00  0.00  0.00   \n",
       "292  0.000  0.000  0.000  0.0  1.000  0.000  0.000  0.000  0.00  0.00  0.00   \n",
       "560  0.000  1.000  0.000  0.0  0.000  0.000  0.000  0.000  0.00  0.00  0.00   \n",
       "84   0.000  0.000  0.000  1.0  0.000  0.000  0.000  0.000  0.00  0.00  0.00   \n",
       "159  0.000  0.000  0.000  0.0  1.000  0.000  0.000  0.000  0.00  0.00  0.00   \n",
       "518  0.000  1.000  0.000  0.0  0.000  0.000  0.000  0.000  0.00  0.00  0.00   \n",
       "224  0.000  0.055  0.945  0.0  0.000  0.000  0.000  0.000  0.00  0.00  0.00   \n",
       "10   0.005  0.000  0.000  0.0  0.175  0.245  0.255  0.155  0.07  0.07  0.03   \n",
       "113  0.000  1.000  0.000  0.0  0.000  0.000  0.000  0.000  0.00  0.00  0.00   \n",
       "428  0.000  0.000  1.000  0.0  0.000  0.000  0.000  0.000  0.00  0.00  0.00   \n",
       "\n",
       "       Z0    Z1     Z2     Z3     Z4     Z5     Z6     Z7     Z8   Z9  \\\n",
       "87   0.00  1.00  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.0   \n",
       "292  0.00  0.00  0.000  0.000  1.000  0.000  0.000  0.000  0.000  0.0   \n",
       "560  0.00  0.03  0.425  0.520  0.015  0.010  0.000  0.000  0.000  0.0   \n",
       "84   0.00  0.00  0.000  1.000  0.000  0.000  0.000  0.000  0.000  0.0   \n",
       "159  1.00  0.00  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.0   \n",
       "518  0.00  0.67  0.330  0.000  0.000  0.000  0.000  0.000  0.000  0.0   \n",
       "224  0.04  0.75  0.210  0.000  0.000  0.000  0.000  0.000  0.000  0.0   \n",
       "10   0.35  0.42  0.130  0.050  0.000  0.025  0.015  0.005  0.005  0.0   \n",
       "113  0.08  0.35  0.565  0.005  0.000  0.000  0.000  0.000  0.000  0.0   \n",
       "428  0.00  0.00  0.000  0.000  1.000  0.000  0.000  0.000  0.000  0.0   \n",
       "\n",
       "         XAVG      YAVG      ZAVG    XPEAK    YPEAK    ZPEAK  XABSOLDEV  \\\n",
       "87  -0.151996  9.794690 -1.258880  36.4151  32.2951  33.0508   0.062255   \n",
       "292  5.179840  3.448410  6.735140  51.3158  52.7778  33.6207   0.127589   \n",
       "560  1.696940 -8.969780  2.418180  76.2500  65.5172  60.3226   1.347730   \n",
       "84   8.506590  1.445730  4.584040  36.7925  30.7937  36.0377   0.074607   \n",
       "159 -6.873570  4.153160 -6.473260  40.8511  38.2000  35.6364   0.028785   \n",
       "518 -2.743000 -9.338500 -0.453747  60.6667  45.8140  44.2857   0.431612   \n",
       "224 -9.233900 -1.365230 -0.632082  68.2143  86.3636  80.0000   0.221781   \n",
       "10   3.901860  8.821500 -1.087800  44.6512  34.7273  32.8070   3.719120   \n",
       "113 -2.407710 -8.796860 -0.127595  58.7097  88.6364  65.5172   1.209220   \n",
       "428  7.261160 -0.603832  6.748650  49.7436  34.6429  50.2703   0.014316   \n",
       "\n",
       "     YABSOLDEV  ZABSOLDEV  XSTANDDEV  YSTANDDEV  ZSTANDDEV      XVAR  \\\n",
       "87    0.022872   0.049490   0.005696   0.002086   0.004751  0.075471   \n",
       "292   0.102453   0.048898   0.011317   0.008817   0.004875  0.106380   \n",
       "560   0.723042   1.144910   0.125610   0.086476   0.104627  0.354415   \n",
       "84    0.048297   0.117841   0.006716   0.004447   0.010113  0.081953   \n",
       "159   0.047126   0.045386   0.002618   0.004013   0.004011  0.051167   \n",
       "518   0.129284   0.822550   0.035667   0.011332   0.063783  0.188857   \n",
       "224   0.358104   0.616038   0.023911   0.036584   0.057271  0.154633   \n",
       "10    3.060620   2.327160   0.317511   0.271342   0.247547  0.563481   \n",
       "113   1.898260   1.166670   0.106734   0.174358   0.112951  0.326701   \n",
       "428   0.005804   0.031875   0.001294   0.000524   0.002870  0.035970   \n",
       "\n",
       "         YVAR      ZVAR    XMFCC0    XMFCC1    XMFCC2    XMFCC3    XMFCC4  \\\n",
       "87   0.045672  0.068926 -0.104081 -0.147114 -0.146878 -0.146484 -0.145934   \n",
       "292  0.093901  0.069823  0.255453  0.361072  0.360492  0.359526  0.358175   \n",
       "560  0.294069  0.323461  0.301150  0.425662  0.424978  0.423839  0.422247   \n",
       "84   0.066689  0.100562  0.323077  0.456656  0.455922  0.454700  0.452992   \n",
       "159  0.063352  0.063329  0.292119  0.412897  0.412234  0.411129  0.409584   \n",
       "518  0.106451  0.252553  0.194561  0.275004  0.274562  0.273826  0.272797   \n",
       "224  0.191270  0.239314  0.340167  0.480812  0.480039  0.478753  0.476954   \n",
       "10   0.520905  0.497541  0.463491  0.655124  0.654072  0.652319  0.649868   \n",
       "113  0.417562  0.336082  0.285235  0.403168  0.402520  0.401441  0.399933   \n",
       "428  0.022892  0.053569  0.299391  0.423176  0.422497  0.421364  0.419781   \n",
       "\n",
       "       XMFCC5    XMFCC6    XMFCC7    XMFCC8    XMFCC9   XMFCC10   XMFCC11  \\\n",
       "87  -0.145227 -0.144365 -0.143348 -0.142178 -0.140855 -0.139382 -0.137759   \n",
       "292  0.356440  0.354324  0.351828  0.348956  0.345710  0.342093  0.338111   \n",
       "560  0.420202  0.417707  0.414765  0.411378  0.407551  0.403288  0.398593   \n",
       "84   0.450798  0.448121  0.444965  0.441332  0.437226  0.432653  0.427616   \n",
       "159  0.407600  0.405180  0.402326  0.399042  0.395330  0.391194  0.386640   \n",
       "518  0.271476  0.269864  0.267963  0.265775  0.263303  0.260549  0.257515   \n",
       "224  0.474644  0.471826  0.468502  0.464677  0.460355  0.455539  0.450236   \n",
       "10   0.646720  0.642880  0.638352  0.633140  0.627251  0.620689  0.613463   \n",
       "113  0.397996  0.395633  0.392846  0.389639  0.386014  0.381976  0.377529   \n",
       "428  0.417748  0.415268  0.412343  0.408976  0.405172  0.400933  0.396266   \n",
       "\n",
       "      XMFCC12    YMFCC0    YMFCC1    YMFCC2    YMFCC3    YMFCC4    YMFCC5  \\\n",
       "87  -0.135989  0.343206  0.485107  0.484328  0.483030  0.481215  0.478884   \n",
       "292  0.333766  0.196979  0.278421  0.277974  0.277229  0.276187  0.274850   \n",
       "560  0.393471  0.372889  0.527063  0.526216  0.524806  0.522833  0.520301   \n",
       "84   0.422121  0.073560  0.103974  0.103806  0.103528  0.103139  0.102640   \n",
       "159  0.381672  0.217395  0.307278  0.306785  0.305962  0.304813  0.303336   \n",
       "518  0.254206  0.334093  0.472226  0.471468  0.470204  0.468437  0.466168   \n",
       "224  0.444450  0.111671  0.157842  0.157588  0.157166  0.156575  0.155817   \n",
       "10   0.605580  0.467915  0.661378  0.660316  0.658546  0.656071  0.652894   \n",
       "113  0.372678  0.378622  0.535166  0.534307  0.532875  0.530872  0.528301   \n",
       "428  0.391174 -0.057794 -0.081689 -0.081558 -0.081339 -0.081033 -0.080641   \n",
       "\n",
       "       YMFCC6    YMFCC7    YMFCC8    YMFCC9   YMFCC10   YMFCC11   YMFCC12  \\\n",
       "87   0.476041  0.472688  0.468828  0.464467  0.459609  0.454258  0.448421   \n",
       "292  0.273218  0.271293  0.269078  0.266575  0.263787  0.260716  0.257365   \n",
       "560  0.517212  0.513569  0.509376  0.504638  0.499359  0.493545  0.487203   \n",
       "84   0.102030  0.101312  0.100484  0.099550  0.098508  0.097362  0.096111   \n",
       "159  0.301535  0.299411  0.296967  0.294204  0.291127  0.287738  0.284040   \n",
       "518  0.463401  0.460137  0.456380  0.452134  0.447405  0.442196  0.436514   \n",
       "224  0.154892  0.153801  0.152545  0.151126  0.149545  0.147804  0.145905   \n",
       "10   0.649017  0.644446  0.639184  0.633238  0.626614  0.619319  0.611361   \n",
       "113  0.525164  0.521465  0.517208  0.512397  0.507037  0.501134  0.494694   \n",
       "428 -0.080162 -0.079597 -0.078948 -0.078213 -0.077395 -0.076494 -0.075511   \n",
       "\n",
       "       ZMFCC0    ZMFCC1    ZMFCC2    ZMFCC3    ZMFCC4    ZMFCC5    ZMFCC6  \\\n",
       "87   0.057287  0.080973  0.080842  0.080626  0.080323  0.079934  0.079459   \n",
       "292  0.288686  0.408046  0.407390  0.406298  0.404771  0.402811  0.400420   \n",
       "560  0.269238  0.380556  0.379944  0.378926  0.377502  0.375674  0.373444   \n",
       "84   0.235690  0.333138  0.332603  0.331711  0.330465  0.328864  0.326912   \n",
       "159  0.283667  0.400951  0.400307  0.399234  0.397734  0.395808  0.393458   \n",
       "518  0.074716  0.105607  0.105438  0.105155  0.104760  0.104253  0.103634   \n",
       "224  0.126810  0.179241  0.178953  0.178473  0.177802  0.176941  0.175891   \n",
       "10   0.445445  0.629617  0.628606  0.626921  0.624565  0.621541  0.617850   \n",
       "113  0.316802  0.447786  0.447067  0.445869  0.444193  0.442042  0.439417   \n",
       "428  0.289290  0.408899  0.408242  0.407148  0.405618  0.403654  0.401257   \n",
       "\n",
       "       ZMFCC7    ZMFCC8    ZMFCC9   ZMFCC10   ZMFCC11   ZMFCC12     XYCOS  \\\n",
       "87   0.078900  0.078255  0.077527  0.076717  0.075823  0.074849 -0.883652   \n",
       "292  0.397599  0.394353  0.390685  0.386598  0.382097  0.377187  0.998417   \n",
       "560  0.370813  0.367786  0.364364  0.360553  0.356355  0.351776 -0.653931   \n",
       "84   0.324609  0.321959  0.318964  0.315627  0.311953  0.307944  0.998715   \n",
       "159  0.390686  0.387496  0.383892  0.379876  0.375454  0.370629 -0.999910   \n",
       "518  0.102904  0.102063  0.101114  0.100056  0.098891  0.097621  0.980796   \n",
       "224  0.174652  0.173226  0.171614  0.169819  0.167842  0.165685  0.928519   \n",
       "10   0.613498  0.608489  0.602829  0.596523  0.589578  0.582002  0.694360   \n",
       "113  0.436322  0.432760  0.428734  0.424249  0.419310  0.413922  0.796771   \n",
       "428  0.398431  0.395178  0.391502  0.387406  0.382896  0.377976 -0.999914   \n",
       "\n",
       "        XZCOS     YZCOS     XYCOR     XZCOR     YZCOR  RESULTANT  \n",
       "87   0.891302 -0.998565 -0.049950  0.359520  0.054988    9.87698  \n",
       "292  0.999308  0.999261 -0.406369 -0.514073 -0.090117    9.17202  \n",
       "560  0.566059 -0.839512  0.312109 -0.061321  0.080221    9.72761  \n",
       "84   0.999143  0.999337 -0.572334 -0.885071  0.566669    9.77228  \n",
       "159  0.999920 -0.999780 -0.244558 -0.566907  0.738233   10.31530  \n",
       "518  0.585169  0.437884 -0.827801  0.886334 -0.745483    9.79916  \n",
       "224  0.602343  0.760343 -0.459482 -0.432456  0.662340    9.40674  \n",
       "10   0.036268 -0.291325  0.308493  0.320320 -0.050466   10.97900  \n",
       "113  0.135824  0.086103 -0.132895  0.129110  0.035064    9.39429  \n",
       "428  0.999968 -0.999927  0.249486 -0.709213 -0.279604    9.93151  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_accel_df_shuffle = shuffle(phone_accel_df)\n",
    "phone_accel_df_shuffle.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_accel_data = phone_accel_df_shuffle.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23074, 91)\n",
      "(23074,)\n"
     ]
    }
   ],
   "source": [
    "X_phone_accel = phone_accel_data[:,1:]\n",
    "Y_phone_accel = phone_accel_data[:,0]\n",
    "print(X_phone_accel.shape)\n",
    "print(Y_phone_accel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_phone_accel, Y_phone_accel, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe, hp, fmin, STATUS_OK,Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [100, 150, 200, 250, 300, 350, 400, 450, 500]),\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 1, 15,1),\n",
    "    \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "    \"min_samples_split\": hp.choice(\"min_samples_split\", [2, 3, 4, 5, 6, 7, 8, 9, 10]),\n",
    "    \"max_features\": hp.choice(\"max_features\", [\"auto\",\"sqrt\",\"log2\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(space):\n",
    "    clf = RandomForestClassifier(**space,n_jobs=-1)\n",
    "    acc = cross_val_score(clf, x_train, y_train,scoring=\"accuracy\").mean()\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [2:47:11<00:00, 100.32s/trial, best loss: -0.8554087671308471]\n",
      "Best: {'criterion': 1, 'max_depth': 15.0, 'max_features': 0, 'min_samples_split': 2, 'n_estimators': 7}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    fn=hyperparameter_tuning,\n",
    "    space = space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=100, \n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "print(\"Best: {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 1,\n",
       " 'max_depth': 15.0,\n",
       " 'max_features': 0,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 7}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9989165176878487\n",
      "Test accuracy:  0.866738894907909\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion = 'entropy', max_depth = 15, max_features = 'auto', min_samples_split = 4, n_estimators = 450, n_jobs = -1)\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(x_train)\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average = Nonen:  [0.94680851 0.94927536 0.87606838 0.90650407 0.88489209 0.92694064\n",
      " 0.89922481 0.89539749 0.81531532 0.84140969 0.87401575 0.87815126\n",
      " 0.75730994 0.81578947 0.82962963 0.92477876 0.89328063 0.73684211]\n",
      "average = micro:  0.866738894907909\n",
      "average = macro:  0.8695352163588475\n",
      "average = weighted:  0.8693043431962947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print(\"average = Nonen: \", precision_score(y_test, y_test_pred, average = None))\n",
    "print(\"average = micro: \", precision_score(y_test, y_test_pred, average = 'micro'))\n",
    "print(\"average = macro: \", precision_score(y_test, y_test_pred, average = 'macro'))\n",
    "print(\"average = weighted: \", precision_score(y_test, y_test_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average = Nonen:  [0.95017794 0.95970696 0.9030837  0.86100386 0.88489209 0.87124464\n",
      " 0.89230769 0.84920635 0.78695652 0.80590717 0.79569892 0.86721992\n",
      " 0.90877193 0.775      0.8358209  0.88185654 0.91497976 0.84677419]\n",
      "average = micro:  0.866738894907909\n",
      "average = macro:  0.8661449484819893\n",
      "average = weighted:  0.866738894907909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(\"average = Nonen: \", recall_score(y_test, y_test_pred, average = None))\n",
    "print(\"average = micro: \", recall_score(y_test, y_test_pred, average = 'micro'))\n",
    "print(\"average = macro: \", recall_score(y_test, y_test_pred, average = 'macro'))\n",
    "print(\"average = weighted: \", recall_score(y_test, y_test_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.1-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from xgboost) (1.19.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from xgboost) (1.5.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space={ 'eta': hp.uniform(\"eta\", 0.001, 0.5),\n",
    "        'max_depth': hp.quniform(\"max_depth\", 3, 30, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,10),\n",
    "        'reg_alpha' : hp.uniform('reg_alpha', 0,20),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.01,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': hp.quniform('n_estimators', 100, 400, 50),\n",
    "        'max_delta_step': hp.quniform('max_delta_step', 0, 10, 1),\n",
    "        'subsample': hp.uniform('subsample', 0.001, 1),\n",
    "        'colsample_bylevel': hp.uniform('colsample_bylevel', 0.01, 1),\n",
    "        'scale_pos_weight': hp.uniform('scale_pos_weaight', 0, 1),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    clf=xgb.XGBClassifier( eta = space['eta'],\n",
    "                    n_estimators =int(space['n_estimators']), max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = space['reg_alpha'], reg_lambda = space['reg_lambda'],\n",
    "                    min_child_weight=int(space['min_child_weight']), colsample_bytree=int(space['colsample_bytree']), \n",
    "                    max_delta_step = space['max_delta_step'], subsample = space['subsample'],\n",
    "                    colsample_bylevel = space['colsample_bylevel'], scale_pos_weight = space['scale_pos_weight'],\n",
    "                    objective = 'multi:softmax')\n",
    "    \n",
    "    evaluation = [( x_train, y_train), ( x_test, y_test)]\n",
    "    \n",
    "    clf.fit(x_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"auc\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:21:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6266522210184182                                                                                                     \n",
      "[03:23:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5568797399783315                                                                                                     \n",
      "[03:24:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6264355362946912                                                                                                     \n",
      "[03:25:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.4008667388949079                                                                                                     \n",
      "[03:25:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.4229685807150596                                                                                                     \n",
      "[03:26:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.39414951245937163                                                                                                    \n",
      "[03:26:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5492957746478874                                                                                                     \n",
      "[03:27:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.36229685807150597                                                                                                    \n",
      "[03:27:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.41278439869989164                                                                                                    \n",
      "[03:27:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6405200433369448                                                                                                     \n",
      "[03:29:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5315276273022752                                                                                                     \n",
      "[03:30:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6585048754062839                                                                                                     \n",
      "[03:32:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.24225352112676057                                                                                                    \n",
      "[03:32:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.4351029252437703                                                                                                     \n",
      "[03:33:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5642470205850487                                                                                                     \n",
      "[03:34:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5915492957746479                                                                                                     \n",
      "[03:35:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5230769230769231                                                                                                     \n",
      "[03:35:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.4455037919826652                                                                                                     \n",
      "[03:36:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5326110509209101                                                                                                     \n",
      "[03:37:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5306608884073672                                                                                                     \n",
      "[03:38:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6140845070422535                                                                                                     \n",
      "[03:39:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5516793066088841                                                                                                     \n",
      "[03:41:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6875406283856988                                                                                                     \n",
      "[03:43:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                                                                 \n",
      "0.6680390032502709                                                                                                     \n",
      "[03:45:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6496208017334778                                                                                                     \n",
      "[03:47:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6745395449620801                                                                                                     \n",
      "[03:49:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6819068255687974                                                                                                     \n",
      "[03:52:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6628385698808233                                                                                                     \n",
      "[03:55:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6179848320693391                                                                                                     \n",
      "[03:56:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6678223185265438                                                                                                     \n",
      "[03:59:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6429035752979415                                                                                                     \n",
      "[04:00:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6390032502708559                                                                                                     \n",
      "[04:02:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6316359696641387                                                                                                     \n",
      "[04:04:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6877573131094258                                                                                                     \n",
      "[04:06:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5570964247020586                                                                                                     \n",
      "[04:07:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                                                                 \n",
      "0.5696641386782232                                                                                                     \n",
      "[04:07:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.618851570964247                                                                                                      \n",
      "[04:09:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6634886240520044                                                                                                     \n",
      "[04:11:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5798483206933911                                                                                                     \n",
      "[04:12:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6281690140845071                                                                                                     \n",
      "[04:14:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6823401950162513                                                                                                     \n",
      "[04:17:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5915492957746479                                                                                                     \n",
      "[04:17:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.638136511375948                                                                                                      \n",
      "[04:19:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5683640303358614                                                                                                     \n",
      "[04:21:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5677139761646804                                                                                                     \n",
      "[04:22:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5601300108342362                                                                                                     \n",
      "[04:23:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6244853737811484                                                                                                     \n",
      "[04:24:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                                                                 \n",
      "0.5453954496208018                                                                                                     \n",
      "[04:25:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5683640303358614                                                                                                     \n",
      "[04:27:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6418201516793066                                                                                                     \n",
      "[04:27:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6394366197183099                                                                                                     \n",
      "[04:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5642470205850487                                                                                                     \n",
      "[04:29:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6396533044420368                                                                                                     \n",
      "[04:30:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.3289274106175515                                                                                                     \n",
      "[04:30:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6290357529794149                                                                                                     \n",
      "[04:31:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6292524377031419                                                                                                     \n",
      "[04:32:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5213434452871073                                                                                                     \n",
      "[04:33:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6762730227518959                                                                                                     \n",
      "[04:35:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5603466955579631                                                                                                     \n",
      "[04:35:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                                                                 \n",
      "0.21083423618634886                                                                                                    \n",
      "[04:35:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6593716143011917                                                                                                     \n",
      "[04:36:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5876489707475623                                                                                                     \n",
      "[04:37:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6136511375947996                                                                                                     \n",
      "[04:38:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6758396533044421                                                                                                     \n",
      "[04:39:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5898158179848321                                                                                                     \n",
      "[04:41:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6799566630552546                                                                                                     \n",
      "[04:42:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6600216684723726                                                                                                     \n",
      "[04:44:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6754062838569881                                                                                                     \n",
      "[04:46:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6721560130010834                                                                                                     \n",
      "[04:47:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6773564463705308                                                                                                     \n",
      "[04:49:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6411700975081257                                                                                                     \n",
      "[04:50:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                                                                 \n",
      "0.657854821235103                                                                                                      \n",
      "[04:51:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6602383531960997                                                                                                     \n",
      "[04:52:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6626218851570964                                                                                                     \n",
      "[04:54:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6316359696641387                                                                                                     \n",
      "[04:55:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6838569880823402                                                                                                     \n",
      "[04:57:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.46825568797399786                                                                                                    \n",
      "[04:57:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6710725893824485                                                                                                     \n",
      "[04:58:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6881906825568798                                                                                                     \n",
      "[05:00:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6101841820151679                                                                                                     \n",
      "[05:00:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6307692307692307                                                                                                     \n",
      "[05:02:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6719393282773565                                                                                                     \n",
      "[05:03:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6541711809317443                                                                                                     \n",
      "[05:04:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                                                                 \n",
      "0.5889490790899241                                                                                                     \n",
      "[05:05:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5958829902491874                                                                                                     \n",
      "[05:06:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6320693391115927                                                                                                     \n",
      "[05:06:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5824485373781149                                                                                                     \n",
      "[05:07:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.533477789815818                                                                                                      \n",
      "[05:08:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.571397616468039                                                                                                      \n",
      "[05:08:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6509209100758396                                                                                                     \n",
      "[05:09:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.4346695557963164                                                                                                     \n",
      "[05:10:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6556879739978332                                                                                                     \n",
      "[05:11:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6216684723726977                                                                                                     \n",
      "[05:12:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.4320693391115926                                                                                                     \n",
      "[05:12:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6485373781148429                                                                                                     \n",
      "[05:13:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                                                                 \n",
      "0.618851570964247                                                                                                      \n",
      "[05:14:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5778981581798484                                                                                                     \n",
      "[05:15:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6123510292524377                                                                                                     \n",
      "[05:16:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.6901408450704225                                                                                                     \n",
      "[05:18:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576:                   \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "SCORE:                                                                                                                 \n",
      "0.5854821235102925                                                                                                     \n",
      "100%|| 100/100 [1:57:06<00:00, 70.27s/trial, best loss: -0.6901408450704225]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bylevel': 0.4826970701942182,\n",
       " 'colsample_bytree': 0.4089965172166954,\n",
       " 'eta': 0.4084770396313456,\n",
       " 'gamma': 1.426537452250675,\n",
       " 'max_delta_step': 1.0,\n",
       " 'max_depth': 18.0,\n",
       " 'min_child_weight': 4.0,\n",
       " 'n_estimators': 400.0,\n",
       " 'reg_alpha': 3.0799688923230546,\n",
       " 'reg_lambda': 0.3680269397122049,\n",
       " 'scale_pos_weight': 0.7013424352411445,\n",
       " 'subsample': 0.8955483204360999}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:04:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[11:04:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Train accuracy:  0.9903570074218538\n",
      "Test accuracy:  0.8680390032502708\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(eta = 0.4, colsample_bytree = 0.409, gamma = 1.43, max_depth = 18, min_child_weight = 4, \n",
    "                        n_estimators = 400, reg_alpha = 3.08, reg_lambda = 0.368, \n",
    "                        colsample_bylevel = 0.483, max_delta_step = 1, scale_pos_weight = 0.7, subsample = 0.89, \n",
    "                        objective = 'multi:softmax')\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(x_train)\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average = Nonen:  [0.93165468 0.92951542 0.89316239 0.88492063 0.875      0.94372294\n",
      " 0.91111111 0.88446215 0.82677165 0.77727273 0.83137255 0.82644628\n",
      " 0.84638554 0.80952381 0.85454545 0.9137931  0.91532258 0.78947368]\n",
      "average = micro:  0.8680390032502708\n",
      "average = macro:  0.8691364841356655\n",
      "average = weighted:  0.8693429462206331\n"
     ]
    }
   ],
   "source": [
    "print(\"average = Nonen: \", precision_score(y_test, y_test_pred, average = None))\n",
    "print(\"average = micro: \", precision_score(y_test, y_test_pred, average = 'micro'))\n",
    "print(\"average = macro: \", precision_score(y_test, y_test_pred, average = 'macro'))\n",
    "print(\"average = weighted: \", precision_score(y_test, y_test_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average = Nonen:  [0.96282528 0.95475113 0.9047619  0.81985294 0.88537549 0.88259109\n",
      " 0.9010989  0.81918819 0.84677419 0.8028169  0.828125   0.85106383\n",
      " 0.91830065 0.80952381 0.83038869 0.86530612 0.86641221 0.87548638]\n",
      "average = micro:  0.8680390032502708\n",
      "average = macro:  0.8680357074496906\n",
      "average = weighted:  0.8680390032502708\n"
     ]
    }
   ],
   "source": [
    "print(\"average = Nonen: \", recall_score(y_test, y_test_pred, average = None))\n",
    "print(\"average = micro: \", recall_score(y_test, y_test_pred, average = 'micro'))\n",
    "print(\"average = macro: \", recall_score(y_test, y_test_pred, average = 'macro'))\n",
    "print(\"average = weighted: \", recall_score(y_test, y_test_pred, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average = Nonen:  [0.94698355 0.94196429 0.89892473 0.85114504 0.88015717 0.91213389\n",
      " 0.90607735 0.85057471 0.83665339 0.78983834 0.8297456  0.83857442\n",
      " 0.88087774 0.80952381 0.84229391 0.88888889 0.89019608 0.8302583 ]\n",
      "average = micro:  0.8680390032502708\n",
      "average = macro:  0.8680450665388402\n",
      "average = weighted:  0.8681313564520392\n"
     ]
    }
   ],
   "source": [
    "print(\"average = Nonen: \", f1_score(y_test, y_test_pred, average = None))\n",
    "print(\"average = micro: \", f1_score(y_test, y_test_pred, average = 'micro'))\n",
    "print(\"average = macro: \", f1_score(y_test, y_test_pred, average = 'macro'))\n",
    "print(\"average = weighted: \", f1_score(y_test, y_test_pred, average = 'weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
